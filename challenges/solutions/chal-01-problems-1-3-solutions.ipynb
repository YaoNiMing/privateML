{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 1\n",
    "- Open up a new ipython notebook\n",
    "- Download a few mta turnstile data files\n",
    "- Open up a file, use csv reader to read it, make a python dict where there is a key for each (C/A, UNIT, SCP, STATION). These are the first four columns. The value for this key should be a list of lists. Each list in the list is the rest of the columns in a row. For example, one key-value pair should look like\n",
    "\n",
    "\n",
    "        {    ('A002','R051','02-00-00','LEXINGTON AVE'):    \n",
    "             [\n",
    "               ['NQR456', 'BMT', '01/03/2015', '03:00:00', 'REGULAR', '0004945474', '0001675324'],          \n",
    "                 ['NQR456', 'BMT', '01/03/2015', '07:00:00', 'REGULAR', '0004945478', '0001675333'],  \n",
    "                ['NQR456', 'BMT', '01/03/2015', '11:00:00', 'REGULAR', '0004945515', '0001675364'],\n",
    "              ...   \n",
    "         ] \n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2016-09-25 12:42:11--  http://web.mta.info/developers/data/nyct/turnstile/turnstile_160903.txt\n",
      "Resolving web.mta.info... 23.72.180.105, 23.72.181.201\n",
      "Connecting to web.mta.info|23.72.180.105|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/plain]\n",
      "Saving to: 'data/turnstile_160903.txt'\n",
      "\n",
      "turnstile_160903.tx     [     <=>            ]  24.13M  1.98MB/s    in 13s     \n",
      "\n",
      "2016-09-25 12:42:24 (1.90 MB/s) - 'data/turnstile_160903.txt' saved [25301340]\n",
      "\n",
      "--2016-09-25 12:42:24--  http://web.mta.info/developers/data/nyct/turnstile/turnstile_160910.txt\n",
      "Resolving web.mta.info... 23.72.180.105, 23.72.181.201\n",
      "Connecting to web.mta.info|23.72.180.105|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/plain]\n",
      "Saving to: 'data/turnstile_160910.txt'\n",
      "\n",
      "turnstile_160910.tx     [                <=> ]  24.35M  1.11MB/s    in 18s     \n",
      "\n",
      "2016-09-25 12:42:42 (1.37 MB/s) - 'data/turnstile_160910.txt' saved [25529149]\n",
      "\n",
      "--2016-09-25 12:42:42--  http://web.mta.info/developers/data/nyct/turnstile/turnstile_160917.txt\n",
      "Resolving web.mta.info... 23.72.180.105, 23.72.181.201\n",
      "Connecting to web.mta.info|23.72.180.105|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/plain]\n",
      "Saving to: 'data/turnstile_160917.txt'\n",
      "\n",
      "turnstile_160917.tx     [          <=>       ]  24.10M  1.85MB/s    in 16s     \n",
      "\n",
      "2016-09-25 12:42:58 (1.52 MB/s) - 'data/turnstile_160917.txt' saved [25267149]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url_template = 'http://web.mta.info/developers/data/nyct/turnstile/turnstile_%s.txt'\n",
    "for date in [160903, 160910, 160917]:\n",
    "    url = url_template % date\n",
    "    !wget --directory-prefix=data/ {url}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv, glob\n",
    "from collections import defaultdict\n",
    "from itertools import islice\n",
    "\n",
    "def read_csv(csv_file_name):\n",
    "\n",
    "    turnstile_to_count_reading = defaultdict(list)\n",
    "    with open(csv_file_name, 'r') as csv_file:\n",
    "        mta_reader = csv.reader(csv_file)\n",
    "        for i, row in enumerate(mta_reader):\n",
    "            # skip the first row, it's just header strings\n",
    "            if i == 0:\n",
    "                continue\n",
    "            # read the rest\n",
    "            turnstile_info = tuple(row[:4])\n",
    "            count_reading = row[4:]\n",
    "            turnstile_to_count_reading[turnstile_info].append(count_reading)\n",
    "    return turnstile_to_count_reading\n",
    "\n",
    "\n",
    "#A) List comprehension\n",
    "weekly_data_dicts = [read_csv(csvfile) for csvfile in glob.glob(\"data/turnstile_*.txt\")]\n",
    "\n",
    "#B) Alternatively, separating the steps on multiple lines\n",
    "# weekly_data_dicts = []\n",
    "# for data_file in glob.glob(\"turnstile_*.txt\"):\n",
    "#    print('Processing %s' % data_file)\n",
    "#    weekly_data_dicts.append(read_csv(data_file))\n",
    "    \n",
    "#(Choose the approach you find more readable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from itertools import islice\n",
    "\n",
    "# just get 2 keys from the first dict to now overwhelm the output\n",
    "sample_dict = dict(weekly_data_dicts[0].items())\n",
    "pprint(sample_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 2\n",
    "- Let's turn this into a time series.\n",
    "\n",
    " For each key (basically the control area, unit, device address and station of a specific turnstile), have a list again, but let the list be comprised of just the point in time and the cumulative count of entries.\n",
    "\n",
    "This basically means keeping only the date, time, and entries fields in each list. You can convert the date and time into datetime objects -- That is a python class that represents a point in time. You can combine the date and time fields into a string and use the [dateutil][1] module to convert it into a datetime object. For an example check [this StackOverflow question][2].\n",
    "\n",
    "Your new dict should look something like\n",
    " \n",
    "    {    ('A002','R051','02-00-00','LEXINGTON AVE'):    \n",
    "             [\n",
    "                [datetime.datetime(2013, 3, 2, 3, 0), 3788],\n",
    "                [datetime.datetime(2013, 3, 2, 7, 0), 2585],\n",
    "                [datetime.datetime(2013, 3, 2, 12, 0), 10653],\n",
    "                [datetime.datetime(2013, 3, 2, 17, 0), 11016],\n",
    "                [datetime.datetime(2013, 3, 2, 23, 0), 10666],\n",
    "                [datetime.datetime(2013, 3, 3, 3, 0), 10814],\n",
    "                [datetime.datetime(2013, 3, 3, 7, 0), 10229],\n",
    "                ...\n",
    "              ],\n",
    "     ....\n",
    "     }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "\n",
    "def count_within_normal_bounds(count):\n",
    "    if count is None:\n",
    "        return True\n",
    "    else:\n",
    "        return 10000 > count >= 0\n",
    "\n",
    "def convert_time_series_to_daily(high_res_time_series):\n",
    "    daily_time_series = []\n",
    "    # I can define a function WITHIN another function. It will only\n",
    "    # be defined within the scope of the mother function\n",
    "    def day_of_timestamp(time_series_entry):\n",
    "        timestamp, tot_entries = time_series_entry\n",
    "        # the .date() method of a datetime object returns the day\n",
    "        #(as another datetime object)\n",
    "        return timestamp.date()\n",
    "    # groupby() requires data to be sorted. It is sorted already here,\n",
    "    # but if it wasn't, we would have to sort it first\n",
    "    count_on_previous_day = None\n",
    "    for day, entries_on_this_day in groupby(high_res_time_series,\n",
    "                                                      key=day_of_timestamp):\n",
    "        # get the maximum cumulative count among the entries on this day\n",
    "        cum_entry_count_on_day = max([count for time, count in entries_on_this_day])\n",
    "        # skip the first entry if we don't know the previous day\n",
    "        if count_on_previous_day is None:\n",
    "            daily_entries = None\n",
    "        else:\n",
    "            daily_entries = cum_entry_count_on_day - count_on_previous_day\n",
    "        # Save today's count for tomorrow's calculation\n",
    "        count_on_previous_day = cum_entry_count_on_day\n",
    "        # Only append if the cumulative increased. Otherwise there is something wrong in the data\n",
    "        # skip with a warning\n",
    "        if count_within_normal_bounds(daily_entries):\n",
    "            daily_time_series.append( (day, daily_entries) )\n",
    "        else:\n",
    "            print('WARNING. Abnormal entry count found '\n",
    "                   'on day %s: %s' % (day, daily_entries))\n",
    "            daily_time_series.append( (day, None) )\n",
    "\n",
    "    return daily_time_series\n",
    "\n",
    "\n",
    "def combine_multiple_weeks_into_single_high_res_timeseries(weekly_time_series):\n",
    "    combined_time_series = defaultdict(list)\n",
    "    for turnstile_to_weeklong_time_series in weekly_time_series:\n",
    "        for turnstile, weeklong_time_series in turnstile_to_weeklong_time_series.items():\n",
    "            combined_time_series[turnstile] += weeklong_time_series\n",
    "    # It's already sorted due to the nature of the files but if not you would want to sort\n",
    "    # the dates first before retiurning it\n",
    "    return combined_time_series\n",
    "\n",
    "\n",
    "def convert_turnstile_to_high_res_time_series_to_daily(turnstile_to_time_series):\n",
    "    turnstile_to_daily_time_series = {}\n",
    "    for i, (turnstile, time_series) in enumerate(turnstile_to_time_series.items()):\n",
    "        print('Processing turnstile', turnstile)\n",
    "        turnstile_to_daily_time_series[turnstile] = convert_time_series_to_daily(time_series)\n",
    "    return turnstile_to_daily_time_series\n",
    "\n",
    "\n",
    "turnstile_to_full_time_series = combine_multiple_weeks_into_single_high_res_timeseries(weekly_time_series)\n",
    "turnstile_to_daily_time_series = convert_turnstile_to_high_res_time_series_to_daily(turnstile_to_full_time_series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def convert_week_data_to_time_series(week_data_dict):\n",
    "    turnstile_to_time_series = defaultdict(list)\n",
    "    for i, (turnstile, row_data) in enumerate(week_data_dict.items()):\n",
    "        # report every 100 turnstiles\n",
    "        if i%100 == 0:\n",
    "            print('Processing turnstile', turnstile)\n",
    "        for lines, division, datestr, timestr, event, cum_entries, cum_exits in row_data:\n",
    "            timestamp = parse('%sT%s' % (datestr,timestr))\n",
    "            turnstile_to_time_series[turnstile].append([timestamp, int(cum_entries)])\n",
    "    return turnstile_to_time_series\n",
    "\n",
    "\n",
    "# this takes a while\n",
    "weekly_time_series = [convert_week_data_to_time_series(item) for item in weekly_data_dicts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Checking the result\n",
    "# just get 2 keys from the first dict to now overwhelm the output\n",
    "sample_turnstile_to_time_series = dict(islice(weekly_time_series[0].items(), 0, 2))\n",
    "pprint(sample_turnstile_to_time_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 3\n",
    "- These counts are cumulative every n hours. We want total daily entries. \n",
    "\n",
    "Now make it that we again have the same keys, but now we have a single value for a single day, which is not cumulative counts but the total number of passengers that entered through this turnstile on this day.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(datetime.date(2016, 8, 27), None),\n",
      " (datetime.date(2016, 8, 28), 677),\n",
      " (datetime.date(2016, 8, 29), 1538),\n",
      " (datetime.date(2016, 8, 30), 1539),\n",
      " (datetime.date(2016, 8, 31), 1508),\n",
      " (datetime.date(2016, 9, 1), 1607),\n",
      " (datetime.date(2016, 9, 2), 1626),\n",
      " (datetime.date(2016, 9, 3), 906),\n",
      " (datetime.date(2016, 9, 4), 666),\n",
      " (datetime.date(2016, 9, 5), 683),\n",
      " (datetime.date(2016, 9, 6), 1399),\n",
      " (datetime.date(2016, 9, 7), 1534),\n",
      " (datetime.date(2016, 9, 8), 1763),\n",
      " (datetime.date(2016, 9, 9), 1686),\n",
      " (datetime.date(2016, 9, 10), 994),\n",
      " (datetime.date(2016, 9, 11), 727),\n",
      " (datetime.date(2016, 9, 12), 1574),\n",
      " (datetime.date(2016, 9, 13), 1724),\n",
      " (datetime.date(2016, 9, 14), 1760),\n",
      " (datetime.date(2016, 9, 15), 1775),\n",
      " (datetime.date(2016, 9, 16), 1790)]\n"
     ]
    }
   ],
   "source": [
    "# Let's check\n",
    "pprint( turnstile_to_daily_time_series[('A002', 'R051', '02-00-00', '59 ST')] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
