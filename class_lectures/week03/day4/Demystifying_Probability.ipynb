{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python 2 & 3 Compatibility\n",
    "from __future__ import print_function, division\n",
    "\n",
    "# Imports\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability Theory\n",
    "We're going to try and do a semester's worth of probability in one morning.  Let's see how this goes...\n",
    "\n",
    "You can use this as a reference more than anything..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Probability?\n",
    "**Two Questions to Ponder:**  \n",
    "1. If I flip a fair coin many times, what is your best guess for the percentage of flips that will come up heads?\n",
    "1. What is the percentage chance that Donald Trump will win the 2016 Presidential Election?\n",
    "\n",
    "These questions are fundamentally different in nature, why?\n",
    "\n",
    "The answer lies in the way they interpret the meaning of probability.  The first relies on what's known as **\"the frequentist interpretation\"** whereas the second discusses probability in terms of a **degree of belief**.\n",
    "\n",
    "#### The Frequentist Viewpoint\n",
    "<img src='img/coin_flip.jpg' align=left style=\"height:120px; padding-right:15px; padding-top:15px; padding-bottom:15px\"/>The frequentist view of probability says that the **probability of an event is the proportion of times that the event would occur in a large (possibly infinite) series of identical trials** of an experiment in which the event is a possible outcome.\n",
    "\n",
    "For coin flipping, this fits our intuition.  We naturally expect that the more flips you have, the closer the number of heads vs tails will get to a 50/50 split.\n",
    "\n",
    "#### Degree of Belief\n",
    "<img src='img/trump.jpg' align=right style=\"height:200px; align:right; padding-left:15px; padding-bottom:10px\"/>\n",
    "The election question requires a different view.  It makes no sense to talk about having millions of elections (although some people may be wanting a do-over on November 9th).  There will only be one trial of this experiment, so what does the \"probability that Trump will win\" really mean?\n",
    "\n",
    "This is where degree of belief comes in.  If we say Trump has a 40% chance, or 0.4 probability of winning, we are imposing our (probably subjective) degree of belief that the event will occur in its one and only trial.\n",
    "\n",
    "#### Which is Right?\n",
    "Ah, an age old mathematical debate.  **The answer truly seems to be both**.  Both interpretations have yielded useful insights and successful actionable decision strategies over centuries of probability theory.  It all depends on the context and what makes sense for the situation under consideration.\n",
    "\n",
    "Both questions in this simple example--and all of probability--deal with **quantifying the likelihood(s) of uncertain events**, but the context can lead to a quite different interpretation as to what that means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <spain id=\"sets\"/>Set Theory\n",
    "To describe probability from first principles, we'll have to introduce some concepts in [**Set Theory**](https://en.wikipedia.org/wiki/Set_theory).\n",
    "\n",
    "#### <span id=\"set_definitions\"/>Definitions:\n",
    "For the notation used here, see the [notation](#set_notation) section below.\n",
    "- **Set**: A collection of objects, which are elements of the set\n",
    "  - e.g.: $\\{Heads, Tails\\}$, or simply $\\{H, T\\}$\n",
    "- **Empty Set**: $\\emptyset$, the set containing no elements\n",
    "- **Countably Infinite Set**: A set with infinitely many elements, but which can be enumerated in a list\n",
    "  - e.g.: All even integers {0, 2, -2, 4, -4, ...}\n",
    "- <span id=\"uncountable\"/>**Uncountable Set**: A set with infinitely many elements which **cannot** be enumerated in a list\n",
    "  - e.g.: All real numbers from 0 to 1: $\\quad \\{ x\\;|\\;0 \\le x \\le 1 \\}$\n",
    "- **Subset**: A set $S$ is a subset of a set $V$ if all elements of $S$ are in $V$\n",
    "  - e.g.: $\\{H\\} \\, \\subset \\{H, T\\}$\n",
    "- **Superset**: A set $S$ is a superset of $V$ if $V$ is a subset of $S$\n",
    "  - e.g.: $\\{H,T\\} \\supset \\{T\\}$\n",
    "- **Universal Set**: $\\Omega$, the set containing all possible elements of interest for a given context\n",
    "  - e.g. for a coin flip: $\\{H, T\\}$\n",
    "- **Complement**: The complement of a set $S^C$ is all of the element in $\\Omega$ but not in $S$\n",
    "  - e.g.: $\\{T\\}^C \\, = \\{H\\}$\n",
    "- **Union**: The union of multiple sets is all elements in **any** of the sets\n",
    "  - e.g.: $\\{T\\} \\cup \\{H\\} \\, = \\{H, T\\}$\n",
    "- **Intersection**: The intersection of multiple sets is all elements that are in **all** of the sets\n",
    "  - e.g.: $\\{T\\} \\cap \\{H, T\\} \\, = \\{T\\}$\n",
    "- **Disjoint**: Two sets are disjoint if they share **no common elements**\n",
    "  - e.g.: $\\{T\\} \\cap \\{H\\} \\, = \\emptyset$\n",
    "- **Partition**: Sets $S$ and $V$ partition another set $W$ if they are **disjoint** and their union covers all of $W$\n",
    "  - e.g. for a coin flip: $\\{T\\}$ and $\\{H\\}$ partition $\\Omega$\n",
    "\n",
    "#### <span id=\"set_notation\"/> Notation:\n",
    "- **Set Membership**:\n",
    "  - Element $x$ in set $S$: $x \\in S$\n",
    "  - Element $x$ not in set $S$: $x \\notin S$\n",
    "  - Elements in a set defined by curly braces: $S = \\{x_1, \\, x_2, \\, ...\\}$\n",
    "  - Set of elements $x$ satisfying property $P$: $S = \\{x \\; | \\; x \\; satisfies \\; P\\}$\n",
    "    - $|$ means \"given\" or \"such that\", so this is \"the set of all elements $x$ such that $x$ satisfies $P$\"\n",
    "    - e.g. [uncountable set](#uncountable)\n",
    "- **Subset**: $\\subset$\n",
    "- **Superset**: $\\supset$\n",
    "- **Complement**: $S^C$\n",
    "- **Union**: \n",
    "  - 2 Sets: $S \\cup V$\n",
    "  - $n$ sets: $\\bigcup\\limits_{i=1}^{n} S_{i} = S_1 \\cup S_2 \\cup S_3, \\, ..., \\, S_n$\n",
    "- **Intersection**:\n",
    "  - 2 Sets: $S \\cap V$\n",
    "  - $n$ Sets: $\\bigcap\\limits_{i=1}^{n} S_{i} = S_1 \\cap S_2 \\cap S_3, \\, ..., \\, S_n$\n",
    "- **Subtraction or Set Difference**: The elements of set $S$ less the elements of set $V$\n",
    "  - $S \\setminus V$\n",
    "- **\"For All\"**: $\\forall$\n",
    "\n",
    "\n",
    "#### <span id=\"visualizing_sets\"/> Visualizing Sets\n",
    "Sets are easily visualized with **Venn Diagrams**:  \n",
    "<img src='img/sets.png'/>\n",
    "\n",
    "##### Checking Understanding\n",
    "Answer the following questions about the Venn Diagrams above:\n",
    "1. What are the unions, intersections, and complements of all sets represented in figured (a)-(f)?\n",
    "1. Which set(s) represent(s) the universal set?\n",
    "1. Which set(s), if any, are subsets or supersets of other sets?\n",
    "1. Which set(s), if any, are disjoint sets?\n",
    "1. Which set(s), if any, form a partition of the universal set?\n",
    "1. How would you write the shaded areas in (a)-(d) in set notation?\n",
    "1. And the non-shaded areas?\n",
    "\n",
    "#### <span id=\"set_identities\"/> Set Identities\n",
    "Combining our [definitions](#set_definitions) with our [notation](#set_notation), and possibly [visualizing sets](#visualizing_sets) we can derive the following useful identities for sets:\n",
    "- **Set Equivalence**: $if \\; S \\subset V \\; and \\; V \\subset S, \\; then \\; S = V$\n",
    "- **Complement**: \n",
    "  - $S^C = \\{x \\in \\Omega \\; | \\; x \\notin S\\}$\n",
    "  - $\\Omega^C = \\emptyset$\n",
    "- **Union**:\n",
    "  - $S \\cup V = \\{x \\; | \\; x \\in S \\; or \\; x \\in V\\}$\n",
    "  - $\\bigcup\\limits_{i=1}^{n}S_i = \\{ x \\; | \\; x \\in S_i \\;\\; for \\; some \\; i\\}$\n",
    "- **Intersection**:\n",
    "  - $S \\cap V = \\{x \\; | \\; x \\in S \\; and \\; x \\in V\\}$\n",
    "  - $\\bigcap\\limits_{i=1}^{n}S_i = \\{ x \\; | \\; x \\in S_i \\;\\; \\forall \\; i\\}$\n",
    "- **Disjoint Sets**: $S$ and $V$ are disjoint if:\n",
    "  - $S \\cap V = \\emptyset$\n",
    "- **Partition**: Sets $S_i$ partition $V$ if:\n",
    "  - $\\bigcup\\limits_{i=1}^{n}S_i = V \\; and \\; S_i \\cap S_j = \\emptyset \\;\\; \\forall \\;\\; i, \\, j$\n",
    "- **Union Commutativity**: $S \\cup V = V \\cup S$\n",
    "- **Union Associativity**: $S \\cup (V \\cup U) = (S \\cup V) \\cup U$\n",
    "- **Distributivity**: \n",
    "  - **Intersection**: $S \\cap (V \\cup U) = (S \\cap V) \\cup (S \\cap U)$\n",
    "  - **Union**: $S \\cup (V \\cap U) = (S \\cup V) \\cap (S \\cup U)$\n",
    "- **Complement**:\n",
    "  - $(S^C)^C = S$\n",
    "  - $S \\cap S^C = \\emptyset$\n",
    "- **Universal Set**:\n",
    "  - $S \\cup \\Omega = \\Omega$\n",
    "  - $S \\cap \\Omega = S$\n",
    "- **De Morgan's Laws**:\n",
    "  - $(\\bigcup\\limits_{i}S_i)^{C} = \\bigcap\\limits_{i}S_{i}^{C}$\n",
    "  - $(\\bigcap\\limits_{i}S_i)^{C} = \\bigcup\\limits_{i}S_{i}^{C}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Events and the Sample Space: Onward to Probability\n",
    "Why did we spend that time on [set theory](#sets)?\n",
    "\n",
    "It's because **sets of events are what drive probability theory**.  Defining the possible outcomes in terms of sets is always the first step toward properly solving a challenging probability question.  Sometimes it's tricky, but thinking about this up front can be huge.\n",
    "\n",
    "### Probability Models\n",
    "A probabilistic model is a mathematical representation of an uncertain situation.  \n",
    "\n",
    "#### Definitions:\n",
    "- **Experiment**: A process that produces exactly one **outcome**\n",
    "  - e.g.: Flipping a coin, the outcome is Heads or Tails\n",
    "  - e.g.: Flipping 3 coins, the outcome is some sequence of Heads/Tails of length 3\n",
    "  - e.g.: Flipping $\\infty$ coins, the outcome is some sequence of Heads/Tails of infinite length\n",
    "  - There is only 1 experiment, and only 1 outcome\n",
    "- **Sample Space**: The **set** of **all possible outcomes** of an experiment\n",
    "  - e.g. for flipping a coin: $\\Omega = \\{H, T\\}$\n",
    "  - e.g. for flipping 3 coins: $\\Omega = \\{HHH, HHT, HTH, HTT, THH, THT, TTH, TTT\\}$\n",
    "  - This is the **Universal Set** for our **experiment context**\n",
    "  - Sample space can be **finite or infinite**\n",
    "    - e.g.: Landing point of an arrow on a target\n",
    "  - **Elements** of the sample space **must be mutually exclusive**, aka can't occur simultaneously\n",
    "  - **Elements** of the sample space **must be collectively exhaustive**, aka one of them will be the result of the experiment\n",
    "- **Event**: A subset of the sample space, aka a **set of possible outcomes** of the experiment\n",
    "  - e.g. for flipping 2 coins: Define event $A$ getting **exactly 1 heads**\n",
    "  - Sample Space: $\\Omega = \\{HH, HT, TH, TT\\}$\n",
    "  - Outcomes Matching Event $A$: $\\{HT, TH\\}$\n",
    "  - A probability law assigns probabilities to every possible event of interest\n",
    "  \n",
    "##### <font color='red'>Probability comes down to assigning relative likelihoods to events.  That's it!</font>\n",
    "  \n",
    "#### Modeling Sequential Processes\n",
    "Many experiments are essentially sequential:\n",
    "- Coin flips: Flip 1 Heads/Tails, then Flip 2 Heads/Tails, then Flip 3, etc\n",
    "- Dice Rolls: Roll 1 1-6, then Roll 2 1-6, then Roll 3, etc\n",
    "- Drawing Cards: Draw 1 card from 52, then 1 card from 51, then 1 card from 50, etc\n",
    "\n",
    "Even if they're not actually being done in sequence, they can be modeled as so.  Often, it's useful to lay out a **grid** or **tree structure** to view all the possible outcomes in the sample space, like so for a pair of 2-sided dice:\n",
    "<img src='img/sequential.png'/>\n",
    "\n",
    "It's (hopefully) immediately clear that the number of possible outcomes in the sample space above is $4\\times4 = 16$ possible outcomes.\n",
    "\n",
    "##### Checking Understanding\n",
    "1. If my experiment is to flip 3 coins in a row, what are all the possible **outcomes**?\n",
    "1. What are some of the possible **events** for this experiment?\n",
    "1. If my experiment is to draw 5 cards from a deck of 52, what are some possible **outcomes**?\n",
    "1. What are some possible **events** for this experiment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Probability Axioms\n",
    "\n",
    "#### Definitions:\n",
    "- **Discrete Outcomes**: Outcomes take on a finite (or countably infinite) set of values\n",
    "- **Continuous Outcomes**: Outcomes take on an uncountably infinite set of values\n",
    "\n",
    "#### Notation:\n",
    "- **Probability of an Event**: Probability that event $A$ occurs\n",
    "  - $P(A)$\n",
    "- **Summation**: $\\sum\\limits_{i=1}^{n}x_i = x_1 + x_2 + x_3 + \\; ... \\; + x_n$\n",
    "- **Product**: $\\prod\\limits_{i=1}^{n}x_i = x_1 \\times x_2 \\times x_3 \\times \\; ... \\; \\times x_n$\n",
    "\n",
    "These are some absolute laws of probability, don't forget them ;)\n",
    "- **Nonnegativity**: $P(A) \\ge 0 \\; \\forall \\; events \\; A$\n",
    "- **Additivity**:\n",
    "  - If Events $A$ and $B$ are disjoint, then $P(A \\cup B) = P(A) + P(B)$\n",
    "  - If all Events $A_i$ are disjoint, then $P(\\bigcup\\limits_{i}A_i) = \\sum\\limits_{i}P(A_i)$\n",
    "- **Normalization or Total Probability**:\n",
    "  - $P(\\Omega) = 1$\n",
    "  - $P(\\emptyset) = 0$\n",
    "  - If collection of Events $A_i$ **partition the sample space** then:\n",
    "    - $\\sum\\limits_{i}P(A_i) = 1$\n",
    "    \n",
    "<font color='red'><b><em>Remember, probability theory is about assigning probabilities to events!</em></b></font>\n",
    "\n",
    "### Experiments with Discrete Outcomes\n",
    "Many experiments have only discrete possible outcomes:\n",
    "- Number of heads in n coin tosses\n",
    "- Sum of 2 6-sided dice rolls\n",
    "- Number of hearts drawn in 10 draws from a 52-card deck\n",
    "\n",
    "We can state some laws about such experiments:\n",
    "#### Discrete Probability Law\n",
    "- Let the possible outcomes of an experiment be represented by the set $\\Omega$ s.t. (such that) $\\{s_1, s_2 s_3, \\; ... \\; ,s_n\\} = \\Omega$.\n",
    "  - e.g. 2 dice rolls: $\\Omega = \\{11, 12, 13, 14, 15, 16, 21, 22, 23, 24, 25, 26, 31, 32, 33, 34, 35, 36, 41, 42, 43, 44, 45, 46, 51, 52, 53, 54, 55, 56, 61, 62, 63, 64, 65, 66\\}$\n",
    "- Define an event $A \\; s.t. \\; A \\subset \\Omega$\n",
    "  - e.g. sum of dice rolls = 7: $A = \\{16, 25, 34, 43, 52, 61\\}$ \n",
    "- This yields:\n",
    "$$\n",
    "\\color{black}{\\bbox[aqua, 8px]\n",
    "{P(A) = \\sum\\limits_{i}\\{s_i \\; | \\; s_i \\in A\\}}}\n",
    "$$\n",
    "\n",
    "Or for our sum of dice rolls...: $P(A) = P(16) + P(25) + P(34) + P(43) + P(52) + P(61) = 6\\times(1/36) = 1/6$\n",
    "  \n",
    "#### Discrete Uniform Probability Law\n",
    "- In the example above, all outcomes in the sample space are equally likely\n",
    "- Aka **they have uniform probability**\n",
    "- When this is true for a sample space $\\Omega$ with $n$ outcomes, we have:\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "P(A) = \\frac{number \\; of \\; elements \\; in \\; A}{n}}\n",
    "$$\n",
    "\n",
    "##### Checking Understanding\n",
    "1. Let's say you toss 3 dice now, what is the probability that you get sum of at least 16?\n",
    "\n",
    "### Experiments with Continuous Outcomes\n",
    "\n",
    "#### Continuous Uniform Probability\n",
    "For continuous variables, outcomes can take on continuous ranges:\n",
    "- The lat/lon of your position at any given time\n",
    "- The x and y coordinates of a dart hitting a dart board\n",
    "- The arrival times of different airlines\n",
    "\n",
    "<font color='red'><b><em>Our events representation happily extends to such ranges of values as well!</em></b></font>  We will see more later.\n",
    "\n",
    "### More Basic Probability Laws\n",
    "Consider events $A$, $B$, and $C$:\n",
    "- **Subset**: If $A \\subset B$, then $P(A) \\le P(B)$\n",
    "- **Union**: $P(A \\cup B) = P(A) + P(B) - P(A \\cap B)$\n",
    "  - **Exercise**: Prove this with a venn diagram\n",
    "  - **Exercise**: Demonstrate this with 3 coin flips\n",
    "    - Let $A$ be the probability of exactly 2 heads\n",
    "    - Let $B$ be the probability of at least 2 heads\n",
    "    - Is there a simpler proof of this than the union rule?\n",
    "- **Union**: $P(A \\cup B) \\le P(A) + P(B)$\n",
    "  - **Generally**: $P(\\bigcup\\limits_{i}A_i) \\le \\sum\\limits_{i}P(A_i)$\n",
    "- **Union**: $P(A \\cup B \\cup C) = P(A) + P(A^C \\cap B) + P(A^C \\cap B^C \\cap C)$\n",
    "  - **Challenge**: Can you prove this with a venn diagram?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Probability\n",
    "Sometimes we want to know the probability that an event occurred **given that another event has already occurred**.  For this, we use laws of **conditional probability**.\n",
    "- Given that the sum of the dice was 9, what's the probability that the first roll was a 6?\n",
    "- Given that the first letter is in a word is \"t\", how likely is the 2nd letter to be \"h\"?\n",
    "- Given a positive biopsy, how likely is it that a person has cancer?\n",
    "- Given an email, how likely is it that it is spam?\n",
    "\n",
    "#### Notation:\n",
    "- **Conditional Probability**: Probability of event $A$ occurring given that you know event $B$ occurred\n",
    "  - $P(A \\; | \\; B)$\n",
    "  \n",
    "### Visualizing Conditional Probability\n",
    "Let's visualize what happens when we condition one **event** on another:\n",
    "- Let's examine the last 6 World Series (2010-2015)\n",
    "- A sneaky demon rolls an invisible (to you) 6-sided di with the numbers 1-6 representing the years 2010-2015\n",
    "- Define the event $A$ to be the probability that the demon rolled a 3\n",
    "- Define the event $B$ to be the Giants winning the World Series in the year of the di\n",
    "- The demon is going to tell you whether the Giants won the world series in the year he rolled, but first he wants you to tell him the probability that he just rolled a 3, what do you say?\n",
    "\n",
    "This is obviously a simple problem, but it's instructive.  Let's use a sample space diagram to examine the problem before our demon's big reveal:\n",
    "<img src='img/before.png'/>\n",
    "Being the smart data scientist you are you confidently tell the demon that the probability he rolled a 3 is $P(A) = 1/6$ using the Discrete Uniform Probability Law from earlier.\n",
    "\n",
    "Now the demon tells you that the Giants won the World Series in the year he rolled.  How does this change your answer?\n",
    "\n",
    "Well let's take a look:\n",
    "<img src='img/after.png'/>\n",
    "Aha, now you see there are only 3 possibilities as you know the Giants win the World Series in all even years, 2010, 2012, and 2014.  You now confidently answer that the probability that he rolled a 3 (aka 2012) is $P(A) = 1/3$.\n",
    "\n",
    "##### What happened?\n",
    "Well, the answer is conditional probability happened.  What conditional probability is doing is simply reducing the sample space (previously $\\Omega$ with 6 possible year outcomes) down to all the outcomes contained in the conditioning event $B$.  That leaves only 3 options, and since you know they're still equally probable you update your answer to $P(A \\; | \\; B) = 1/3$.\n",
    "\n",
    "### Conditional Probability Identities\n",
    "- **Uniform Probability of Outcomes**: $P(A | B) = \\frac{number \\; of \\; elements \\; of \\; A \\cap B}{number \\; of \\; elements \\; of \\; B}$\n",
    "\n",
    "Or, generalizing:\n",
    "$$\n",
    "\\bbox[aqua]{\n",
    "P(A | B) = \\frac{P(A \\cap B)}{P(B)}\n",
    "}\n",
    "$$\n",
    "\n",
    "We can flip this for perhaps a more useful version:\n",
    "$$\n",
    "\\bbox[aqua]{\n",
    "P(A \\cap B) = P(A | B) \\times P(B)\n",
    "}\n",
    "$$\n",
    "\n",
    "#### Conditional Multiplication Rule\n",
    "What if we want to know the probability of many simultaneous events occurring?  With conditional probability, that's easy to write down as such:\n",
    "$$\n",
    "\\bbox[aqua]{\n",
    "P(\\bigcap\\limits_{i=1}^{n}A_i) = P(A_1)\\times P(A_2 | A_1) \\times P(A_3 | A_1 \\cap A_2) \\; ... \\; \\times P(A_n | \\bigcap\\limits_{i=1}^{n-1}A_i)\n",
    "}\n",
    "$$\n",
    "\n",
    "Basically, **each multiplication term is just conditioned on all the previous events having occurred.**\n",
    "\n",
    "##### Checking Understanding\n",
    "In a game of 5-card draw in a 52-card deck (4 suits of 13 cards each), what is the probability of drawing a flush (5 cards of all the same suit)?\n",
    "\n",
    "#### Total Probability Theorem\n",
    "Let there be $n$ events $\\{A_1, A_2, \\; ... \\;, A_n\\}$ which partition the sample space (disjoint and exhaustive) of all possible outcomes.  Then, for **any event B**:\n",
    "$$\n",
    "\\bbox[aqua]{\n",
    "P(B) = \\sum\\limits_{i}P(B \\cap A_i) = \\sum\\limits_{i}(P(A_i)\\times P(B | A_i)\n",
    "}\n",
    "$$\n",
    "\n",
    "##### Checking Understanding\n",
    "You're Rex Ryan coaching the Bills and playing the New England Patriots this weekend.  Your probability of beating them is dependent on who is starting at quarterback for them.  You know the following facts:\n",
    "- If Jimmy Garoppolo plays (probability 0.2) you have a 30% chance of winning.\n",
    "- If Jacoby Brissett plays (probability 0.7) you have a 40% chance of winning.\n",
    "- If Julian Edelman plays (probability 0.09) you have a 60% chance of winning.\n",
    "- If Tom Brady sneaks onto the field in disguise and plays (probability 0.01) you have a 10% chance of winning.\n",
    "- What is your total probability of winning?\n",
    "\n",
    "#### Bayes' Theorem\n",
    "Finally let's put everything together to derive the celebrated **Bayes' Theorem**.\n",
    "- Assume again you have events $A_i$ that partition the sample space\n",
    "- You observe some event $B$\n",
    "- You want to know which of the $A_i$ events most likely occurred\n",
    "- Intersection is commutative, so $P(A_i \\cap B) = P(B \\cap A_i)$\n",
    "- Plugging in our conditional probability equations on both sides and using the total law of probability we arrive at:\n",
    "$$\n",
    "\\bbox[aqua]{\n",
    "P(A_i | B) = \\frac{P(A_i)\\times P(B | A_i)}{P(B)} = \\frac{P(A_i)\\times P(B | A_i)}{\\sum\\limits_{i}(P(A_i)\\times P(B | A_i)}\n",
    "}\n",
    "$$\n",
    "\n",
    "##### Checking Understanding\n",
    "You managed to beat the Patriots!  However, you're Rex Ryan so you got drunk and slept through the game.  You're curious to know which of the Patriots' quarterbacks actually ended up playing.  Using the information above and your newfound winning knowledge, how likely would you rate the chances for each quarterback having played?\n",
    "\n",
    "### Independence\n",
    "Independence between 2 events means that knowing one event has occurred doesn't affect the probability of the other one occurring.\n",
    "\n",
    "Or, in other words:\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "P(A | B) = P(A)\n",
    "}\n",
    "$$\n",
    "\n",
    "This also leads to:\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "P(A \\cap B) = P(A) \\times P(B)\n",
    "}\n",
    "$$\n",
    "\n",
    "And **generally** for many events:\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "P(\\bigcap\\limits_{i}A_i) = \\prod\\limits_{i}P(A_i)\n",
    "}\n",
    "$$\n",
    "\n",
    "##### Checking Understanding\n",
    "1. When flipping coins, are the events \"you got a Heads on the first toss\" and \"you got a Heads on the second toss\" independent events?\n",
    "1. When drawing cards, are the events \"you got a Heart on the first draw\" and \"you got a Heart on the 2nd draw\" independent events?\n",
    "\n",
    "#### Conditional Independence\n",
    "Sometimes 2 events aren't normally independent but they can become independent when some other event is known to have occurred.\n",
    "\n",
    "This is captured by the following equalities holding:\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "P(A \\cap B | C) = P(A | C) \\times P(B | C) = \\frac{P(A \\cap B \\cap C)}{P(C)} = P(B | C)\\times P(A | B \\cap C)\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting\n",
    "We have seen 2 instances already where calculating the **probability of an event $A$** simply boils down to **counting** the number of experiment outcomes satisfying $A$.  That is:\n",
    "- When the sample space $\\Omega$ is **discrete** and **finite**, with each possible outcome equally likely, we have:\n",
    "$$\n",
    "P(A) = \\frac{number \\; of \\; elements \\; \\in \\; A}{number \\; of \\; elements \\; \\in \\; \\Omega}\n",
    "$$\n",
    "- When all outcomes are equally likely with known probability $p$, we have:\n",
    "$$\n",
    "P(A) = p\\cdot (number \\; of \\; elements \\; \\in \\; A)\n",
    "$$\n",
    "- Thus, **finding $P(A)$ is an exercise in counting elements in $A$ and/or $\\Omega$**\n",
    "  - This study of **counting** is known as **combinatorics**\n",
    "  \n",
    "### Outcomes of a Multi-stage Process\n",
    "- Consider a process modeled as $r$ stages\n",
    "  - e.g.: Possible 7-digit telephone #s\n",
    "- At the $i$th stage, there are $n_i$ possibilities given the previous $i-1$ stages\n",
    "- The **total number of possible outcomes is**: $\\prod\\limits_{i=1}^{r}n_i$\n",
    "  - e.g.: Telephone #s: \n",
    "    - The first digit can be any # 2-9\n",
    "    - The remaining digit can be any number (assumption) 0-9\n",
    "    - $possibilities = 8\\cdot10\\cdot10\\cdot10\\cdot10\\cdot10\\cdot10 = 8\\cdot10^6 = 8,000,000$\n",
    "\n",
    "#### Subsets of an n-element Set\n",
    "- Consider a set $S$ of $n$ elements\n",
    "  - e.g.: You all!  $n=24$ students\n",
    "- What is the total number of subsets of $S$?\n",
    "  - e.g.: The possible combinations of people showing up for my lecture today!\n",
    "- Think of $n$-stage process with 2 possible outcomes at each (element either in subset or not)\n",
    "- $\\# \\; of \\; subsets = 2^n$\n",
    "  - e.g.: Number of possible classes: $2^{24} = 16,777,216$!!!\n",
    "  \n",
    "### Selecting $k$ Objects from $n$-element Set\n",
    "We'll focus on 2 scenarios for selecting $k$ objects out of an $n$-element set:\n",
    "1. **(k-)Permutations**: when the order matters (aka different orderings are distinct results)\n",
    "  - e.g. Selecting 7 ($k$) lottery ping pong balls from 100 ($n$) balls with integers 1-100\n",
    "2. **(k-)Combinations**: Order doesn't matter (different orderings are equivalent)\n",
    "  - e.g. Getting $k$ heads in $n$ tosses\n",
    "\n",
    "#### k-Permutations\n",
    "- This is a multi-stage process of $k$ stages\n",
    "- **Order matters**: $\\{2, 7, 4\\} \\ne \\{7, 2, 4\\}$\n",
    "- At the $i$th stage, we have $n-i+1$ choices\n",
    "- Thus, the number of k-permutations (distinct sequences of length k) is:\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "\\mathbf{\\# k-permutations} = \\prod\\limits_{i=1}^{k}(n-i+1) = n\\cdot(n-1)\\cdot\\cdots\\cdot(n-k+1) = \\frac{n\\cdot(n-1)\\cdot\\cdots\\cdot(n-k+1)\\cdot(n-k)\\cdot\\cdots\\cdot2\\cdot1}{(n-k)\\cdot(n-k-1)\\cdot\\cdots\\cdot2\\cdot1} = \\mathbf{\\frac{n!}{(n-k)!}}\n",
    "}\n",
    "$$\n",
    "  - e.g. Winning #s: 7 of 100 ping pong balls: $\\frac{100!}{93!} \\approx 80,678,106,400,000$ or 1 in *80 trillion*\n",
    "- **Special Case**: $k=n\\rightarrow n!\\rightarrow$ all permutations of set\n",
    "\n",
    "#### k-Combinations\n",
    "- This is a multi-stage process of $k$ stages\n",
    "- **However**, this time **order doesn't matter**\n",
    "- Simple!  **Take our k-permutations and divide by all possible combinations of the k objects**!\n",
    "- **Permutations of k objects**: $k!$\n",
    "- **k-Permutations**: $\\frac{n!}{(n-k)!}$\n",
    "- Thus, we have:\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "\\mathbf{\\# k-combinations} = \\frac{\\# \\; k-permutations}{\\# \\; permutations \\; of \\; k \\; objects} = \\mathbf{\\frac{n!}{(n-k)!k!}} = {n \\choose k}\n",
    "}\n",
    "$$\n",
    "- This is known as the **Binomial Coefficient**: ${n \\choose k}$ is read \"n choose k\"\n",
    "  - Number of ways to choose k objects from n-element set\n",
    "  \n",
    "  - e.g. $k$ heads in $n$ flips: ${n \\choose k}$ possibilities\n",
    "  - Here's a plot of what this looks like for $n=20$:\n",
    "<img src='img/choose.png'/ style='height:400px; width:800px'>\n",
    "\n",
    "#### Partitions\n",
    "- Combinations partition all elements into **2 disjoint subsets**: either **in** or **not in**\n",
    "  - e.g.: The $k$ heads are \"in\", and the $n-k$ tailes are \"not in\"\n",
    "- What if we have **more than 2 possible subsets**?\n",
    "- Consider $n$-element set $S$\n",
    "- Consider $r$ disjoint subsets, or bins, for the $n$ elements\n",
    "- Let the number of elements put in each bin be $n_1, n_2, \\cdots, n_r$, where $\\sum\\limits_{i=1}^{r}n_i = n$\n",
    "- Can model as $r$-stage multistage process, choosing bins one at a time\n",
    "  - To form the first bin: ${n \\choose n_1}$ ways\n",
    "  - Now there are only $n-n_1$ elements left, so to form 2nd bin: ${n-n_1 \\choose n_2}$ ways\n",
    "  - For 3rd: ${n-n_1-n2 \\choose n_3}$ ways\n",
    "  - And so on...yields:\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "\\begin{align}{n \\choose n_1}{n-n_1 \\choose n_2}\\cdots{n-n_1-\\cdots-n_{r-1} \\choose n_r} & = \\frac{n!}{n_1!(n-n_1)!}\\cdot\\frac{(n-n_1)!}{n_2!(n-n_1-n_2)!}\\cdots\\frac{(n-n_1-\\cdots-n_{r-1})!}{n_r!(n-n_1-\\cdots-n_{r-1}-n_r)!} \\\\ & = \\frac{n!}{n_1!n_2!\\cdots n_r!} \\\\ & = {n \\choose n_1, n_2, \\cdots ,n_r}\n",
    "\\end{align}\n",
    "}\n",
    "$$\n",
    "- This is known as the **Multinomial Coefficient**\n",
    "- e.g.: Anagrams: How many different words (character orderings, not valid words) can be made by scrambling the word \"tattoo\"?\n",
    "  - There are 6 elements here, but only 3 partitions\n",
    "  - The number of each partition is 3 (t), 2 (o), and 1\n",
    "  - Thus we have: $\\frac{6!}{3!2!1!} = 5\\cdot 4\\cdot 3 = 60$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Distributions and Random Variables\n",
    "\n",
    "- So far, we've been concerned with probabilities of specific **outcomes** and **events** (sets of outcomes)\n",
    "- Now, we'll introduce **random variables** to encode the likelihoods of all possible outcomes in 1 variable!\n",
    "\n",
    "#### Definitions\n",
    "- **Random Variable** (R.V.) $X$ is a real-valued function of experimental outcomes.  It maps experimental outcomes to numeric values.\n",
    "  - e.g.: The number of heads in 10 tosses\n",
    "  - e.g.: The sum of the rolls of 2 dice\n",
    "  - e.g.: The amount of time for me to respond to your Slack questions\n",
    "- **Probability Distribution**: Specifies some measure of the **probability** of every possible value of a R.V.\n",
    "- **Discrete Random Variable**: a R.V. whose range is discrete or countably infinite\n",
    "  - e.g.: coin flips\n",
    "- **Continuous Random Variable**: a R.V. whose range is uncountably infinite\n",
    "  - e.g. Slack response time\n",
    "- **Probability Mass Function (PMF)**: Maps value $x$ of **discrete R.V.** $X$ to associated **probability** $P(X=x)$ for all possible $x$\n",
    "  - This is a **Discrete Probability Distribution**\n",
    "- **Probability Density Function (PDF)**: Maps value $x$ of **continuous R.V.** $X$ to associated **probability density** $p(X=x)$ for all possible $x$\n",
    "  - This is a **Continuous Probability Distribution**\n",
    "- **Sampling**: Choosing objects from a population according to some prescribed probabilities (could be random!)\n",
    "- **Sampling *with* Replacement**: After each object is sampled from the population, it is put back in so that it could be chosen again\n",
    "- **Sampling *without* Replacement**: After each object is sampled, it is not put back in, so we can never get it again\n",
    "- **Independent, Identically Distributed, or I.I.D.**: Variables that have identical probability distributions and are independent of one another\n",
    "  \n",
    "##### Notation\n",
    "- **PMF**: $p_{X}(x)$ is the probability associated with the discrete R.V. $X$ for all $x$\n",
    "- **PDF**: $f_{X}(x)$ is the **probability density** for continuous R.V. $X$ for all $x$\n",
    "\n",
    "**Example of a PMF: Flipping Coins (Binomial Distribution)**  \n",
    "$X$ is the number of heads $k$ in $n$ tosses.  Each value of $k$ in 0 to $n$ has some probability:\n",
    "$$\n",
    "p_X(k) = {n \\choose k}p^k(1-p)^{n-k}, \\quad k=0, 1, \\cdots, n\n",
    "$$\n",
    "<img src='img/coins.png'/>\n",
    "\n",
    "**Example of a PDF: Normal Curve**  \n",
    "The heights of a population are more or less normally distributed, aka the average has the highest probability with decreasing probabilities above or below that:\n",
    "$$\n",
    "f_X(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\n",
    "$$\n",
    "<img src='img/heights.jpg'/>\n",
    "\n",
    "#### Discussion of Probability Densities\n",
    "- For PMFs, each discrete outcome has a tangible probability\n",
    "- For PDFs, we speak instead of a **probability density**\n",
    "- **Probability Densities are not probabilities**\n",
    "- Because continuous R.V.s have uncountably infinite numbers of possibilities, we cannot assign discrete probabilities to any one value\n",
    "  - $P(X=x) = 0 \\; \\forall \\; x$\n",
    "- We can only assign relative likelihoods, represented by the probability density, $f_X(x)$\n",
    "- **We can ascribe distinct probabilities to ranges of values for Continuous R.V.s, as such**:\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "P(X \\in B) = \\int\\limits_B f_X(x)dx \\rightarrow P(a \\le x \\le b) = \\int\\limits_a^b f_X(x)dx\n",
    "}\n",
    "$$\n",
    "- Here $B$ represents some set of potential values, and $a$ and $b$ represent constants as lower and upper bounds of a range\n",
    "\n",
    "##### But why an Integral?\n",
    "- Interpret Probability Density $f_X(x)$ for R.V. $X$ s.t. the probability of $X$ in some range represents the area under the curve of $f_X$ in that range\n",
    "- Visually: <img src='img/pdf.png'/>\n",
    "<img src='img/pdf2.png' align=right style=\"height:180px; align:right; padding-left:15px; padding-bottom:10px\"/>\n",
    "\n",
    "<br/>\n",
    "- If we interpret $f_X(x)$ as the **probability mass per unit length around $x$**, then we can see how this leads to an integral interpretation as shown in the plot to the right. \n",
    "- The probability of the small range covered by $\\delta$ will be $f_x(x)\\cdot\\delta$, and taking $\\delta \\rightarrow 0$ and the summation over a range leads to the integral.\n",
    "\n",
    "**Normalization:**  \n",
    "- To be a valid probability, we must have **total probability add up to 1**, so lastly:\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "\\int\\limits_{-\\infty}^{\\infty}f_X(x)dx = 1\n",
    "}\n",
    "$$\n",
    "\n",
    "### Functions of Random Variables\n",
    "- **If we can state a probability distribution for a R.V. $X$, then we can do it for a function $Y=g(X)$**.\n",
    "- $Y$ is a R.V.: it has a probability distribution\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "p_Y(y) = \\sum\\limits_{x|g(x)=y}p_X(x)\n",
    "}\n",
    "$$\n",
    "\n",
    "### Expectation, Mean, and Variance of a Random Variable\n",
    "Here we discuss some important variables that can be associated with a random variable $X$ (and thus with a probability distribution for $X$).\n",
    "\n",
    "##### Definitions\n",
    "- **Expectation aka Mean or Expected Value**: A weighted (by the probability (density)) average of the possible values of $X$\n",
    "- **Variance**: How widely dispersed (varied) $X$ is about its mean\n",
    "- **Standard Deviation**: The square root of the Variance\n",
    "\n",
    "##### Notation\n",
    "- **Expectation**: $E[X]$\n",
    "- **Mean**: $\\mu_X$\n",
    "- **Variance**: $var(X)=\\sigma^2$\n",
    "- **Standard Deviation**: $\\sigma_X=\\sqrt{var(x)}$\n",
    "\n",
    "#### Formulas and Identities\n",
    "Here are some formulae about expectation and variance:\n",
    "\n",
    "##### All R.V.s\n",
    "- **Variance**: Variance is the expected value of the R.V. $(X-E[X])^2$\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "var(X) = E[(X-E[X])^2]\n",
    "}\n",
    "$$\n",
    "- **Variance** again: $var(X)=E[X^2]-E[X]^2$\n",
    "- **Linear Functions**: If $Y=aX+b$ is a linear function of R.V. $X$ then: \n",
    "  - $E[Y] = aE[X] + b$\n",
    "  - $var(Y) = a^2var(X)$\n",
    "\n",
    "##### Discrete R.V.s\n",
    "- **Expectation**: The expectation is just a weighted sum of the probability of each value and the value itself\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "E[X] = \\sum\\limits_xxp_X(x)\n",
    "}\n",
    "$$\n",
    "- **Expectation of Functions of a R.V.**: If $Y=g(X)$ is some function of the R.V. $X$ then:\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "E[g(X)] = \\sum\\limits_xg(x)p_X(x)\n",
    "}\n",
    "$$\n",
    "- **Variance**: $g(X) = (X-E[X])^2$ is a function of $X$ and $var(X) = E[g(X)]$ so:\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "var(X) = \\sum\\limits_x(x-E[X])^2p_X(x)\n",
    "}\n",
    "$$\n",
    "\n",
    "##### Continuous R.V.s\n",
    "- **Basic Formula**: The expectation is an integral over the analogous quantity from the discrete case\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "E[X] = \\int\\limits_xxf_X(x)dx\n",
    "}\n",
    "$$\n",
    "- **Functions of a R.V.**: If $Y=g(X)$ is some function of the R.V. $X$ then:\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "E[g(X)] = \\int\\limits_xg(x)f_X(x)dx\n",
    "}\n",
    "$$\n",
    "- **Variance**: $g(X) = (X-E[X])^2$ is a function of $X$ and $var(X) = E[g(X)]$ so:\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "var(X) = \\int\\limits_x(x-E[X])^2f_X(x)\n",
    "}\n",
    "$$\n",
    "  \n",
    "### Common Discrete R.V.s\n",
    "It's important to know common probability distributions for both discrete and continuous R.V.s.  Here are a few for discrete (there are always more):\n",
    "\n",
    "#### Bernoulli\n",
    "- Single trial with probability of success $p$ and failure $1-p$\n",
    "  - e.g.: X = number of heads in 1 toss of a coin with probability $p$ of a heads\n",
    "- **Parameters**:\n",
    "  - $p$: Probability of success on a trial\n",
    "- **Expectation**: $p$\n",
    "- **Variance**: $p(1-p)$\n",
    "- **PMF**:\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "X = \\begin{cases}1, & \\text{if heads}\\\\0, & \\text{if tails}\\end{cases}\n",
    "}\n",
    "$$\n",
    "- Here's the pmf:\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "p_X(k) = \\begin{cases}p, & \\text{if }\\; k=1\\\\ 1-p, & \\text{if }\\; k=0\\end{cases}\n",
    "}\n",
    "$$\n",
    "\n",
    "#### Binomial\n",
    "- In a sequence of independent Bernoulli trials, the number of \"successes\"\n",
    "- This is a **Sum of Bernoulli R.V.s**\n",
    "  - e.g.: X = number of heads in $n$ tosses, aka $n$ independent trials of a Bernoulli experiment\n",
    "- **Parameters**:\n",
    "  - $n$: Number of trials\n",
    "  - $p$: Probability of success on any given trial\n",
    "- **Expectation**: $np$\n",
    "- **Variance**: $np(1-p)$\n",
    "- We already know the pmf for this!\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "p_X(k) = {n \\choose k}p^k(1-p)^{n-k}, \\quad k=0, 1, \\cdots, n\n",
    "}\n",
    "$$\n",
    "- Taking a look: <img src='img/binomial.png'/>\n",
    "- Binomial is symmetric if $p=0.5$\n",
    "- **Long tail toward n** aka **positive skew** aka **skewed right** if $p\\lt0.5$\n",
    "- **Long tail toward 0** aka **negative skew** aka **skewed left** if $p\\gt0.5$\n",
    "\n",
    "#### Geometric\n",
    "- In a sequence of independent Bernoulli trials, the number of trials up to and including the first success\n",
    "  - e.g.: Number of flips to get first head\n",
    "- **Parameters**:\n",
    "  - $p$: Probability of success on any given trial\n",
    "- **Expectation**: $1/p$\n",
    "- **Variance**: $(1-p)/p^2$\n",
    "- PMF:\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "p_X(k) = (1-p)^{k-1}p \\quad k=1,2,\\cdots\n",
    "}\n",
    "$$\n",
    "- This is like $k-1$ failures ($(1-p)^{k-1}$) followed by that first success ($p$)\n",
    "- Let's take a look: <img src='img/geometric.png' style='height:400px'/>\n",
    "\n",
    "#### Poisson\n",
    "- (Effectively) a Binomial R.V. where $n$ is very large and $p$ very small, $n \\gt\\gt p$\n",
    "  - e.g.: Error/Failure rates in computing\n",
    "- **Parameters**:\n",
    "  - $\\lambda$: Controls the shape, similar to $np$ for Binomial\n",
    "- **Expectation**: $\\lambda$\n",
    "- **Variance**: $\\lambda$\n",
    "- **PMF**:\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "p_X(k) = e^{-\\lambda}\\frac{\\lambda^k}{k!} \\quad k=1,2,\\cdots\n",
    "}\n",
    "$$\n",
    "- $\\lambda \\approx np$ from Binomial in $n \\gt \\gt p$ limit\n",
    "- Here's what it looks like: <img src='img/poisson.png'/>\n",
    "\n",
    "#### Discrete Uniform\n",
    "- A discrete R.V. where every outcome has equal probability\n",
    "  - e.g.: Random number generator\n",
    "- **Parameters**:\n",
    "  - $n$: Number of discrete outcomes\n",
    "- **Expectation**: $(a+b)/2$\n",
    "- **Variance**: $((b-a+1)^2-1)/12$\n",
    "- **PMF**:\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "p_X(k) = 1/n \\quad k=\\{k_1, k_2, \\cdots , k_n\\}\n",
    "}\n",
    "$$\n",
    "- Let's take a look: <img src='img/discrete_uniform.jpg'/>\n",
    "\n",
    "#### Hypergeometric\n",
    "- In a population with $N$ elements, of which $K$ represent a \"success\", this R.V. is the probability of $k$ successes in $n$ draws\n",
    "- **Parameters**:\n",
    "  - $N$: Total objects in the whole population\n",
    "  - $K$: Total successes in the whole population\n",
    "  - $n$: Total draws (without replacement)\n",
    "- The **binomial distribution** is like $n$ draws of probability $p=K/N$ **with replacement**, whereas the **hypergeometric** is like sampling **without replacement**\n",
    "  - e.g.: Drawing Cards: Number, $k$, of Hearts in $n$ draws\n",
    "      - $N=52 = \\text{cards in deck}$\n",
    "      - $K=13 = \\text{hearts in deck}$\n",
    "- **Expectation**: $nK/N$\n",
    "- **Variance**: $n\\frac{K}{N}\\frac{N-K}{N}\\frac{N-n}{N-1}$\n",
    "- **PMF**:\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "p_X(k) = \\frac{{K \\choose k}{N - K \\choose n-k}}{{N \\choose n}} \\quad k=1,2,\\cdots , n, \\;\\; n=1,2,\\cdots,N\n",
    "}\n",
    "$$\n",
    "- Let's take a look (**Note**: here $K$ is being called $r$): <img src='img/hypergeometric.png'/>\n",
    "\n",
    "#### Negative Binomial\n",
    "- In a sequence of independent Bernoulli trials with success probability $p$, the number of successes $k$ up to and including the $r$th failure\n",
    "- **Parameters**:\n",
    "  - $p$: Probability of a success on any given trial\n",
    "  - $r$: Number of failures to stop at\n",
    "- This is just a generalization of the geometric distribution from 1 to $r$ (and focusing on failure vs success)\n",
    "  - e.g.: Number of non-3 dice rolls before you roll 4 3s\n",
    "    - $p=5/6$: probability of a non-3\n",
    "    - $r=4$: Stopping criteria\n",
    "- **Expectation**: $pr/(1-p)$\n",
    "- **Variance**:$\\frac{pr}{(1-p)^2}$\n",
    "- **PMF**:\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "p_X(k) = {k+r-1 \\choose k}(1-p)^{r}p^k \\quad k=1,2,\\cdots\n",
    "}\n",
    "$$\n",
    "- Let's take a look: <img src='img/negative_binomial.png'/>\n",
    "\n",
    "**[So many more Discrete Distributions!](https://en.wikipedia.org/wiki/List_of_probability_distributions#Discrete_distributions)**\n",
    "\n",
    "### Common Continuous R.V.s\n",
    "\n",
    "#### Continuous Uniform\n",
    "- R.V. with constant probability density across the entire range of $X$\n",
    "  - e.g.: Random real number between 0 and 1\n",
    "- **Parameters**:\n",
    "  - $a$: Lower bound of $X$\n",
    "  - $b$: Upper bound of $X$\n",
    "- **Expectation**: $(a+b)/2$\n",
    "- **Variance**: $\\frac{1}{12}(b-a)^2$\n",
    "- **PDF**:\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "f_X(x) = \\begin{cases} \\frac{1}{b-a}, & \\text{if}\\; a \\le x \\le b \\\\ 0, & \\text{otherwise} \\end{cases}\n",
    "}\n",
    "$$\n",
    "- Taking a look: <img src='img/continuous_uniform.png'/>\n",
    "\n",
    "#### Gaussian (Normal) \n",
    "- The normal/bell curve!\n",
    "- **Parameters**:\n",
    "  - $\\mu$: The mean/center of the curve\n",
    "  - $\\sigma$: The standard deviation, quantifies width of the curve\n",
    "    - $\\approx68$% of probability is within 1 standard deviation of the mean\n",
    "    - $\\approx95$% of probability is within 2 standard deviations of the mean\n",
    "    - $\\approx99.7$% of the probability is within 3 standard deviations of the mean\n",
    "- Normal distributions are useful for a number of reasons:\n",
    "  - They pop up a lot\n",
    "  - A gaussian times a gaussian yields another gaussian (we'll come back to this)\n",
    "  - **Central Limit Theorem**: The average value of a large sequence of I.I.D. R.V.s will be normally distributed (we'll come back to this!)\n",
    "- **Standard Normal Distribution**: A gaussian with $\\mu=0$ and $\\sigma=1$\n",
    "- **Expectation**: $\\mu$\n",
    "- **Variance**: $\\sigma^2$\n",
    "- **PDF**:\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "f_X(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\n",
    "}\n",
    "$$\n",
    "- Here's what she looks like: <img src='img/gaussian.png' style='height:400px'/>\n",
    "\n",
    "#### Exponential \n",
    "- Continuous generalization of geometric distribution\n",
    "  - e.g.: Time between failures of a machine\n",
    "- **Parameters**:\n",
    "  - $\\lambda$: Controls how fast the PDF \"decays\"\n",
    "- **Expectation**: $1/\\lambda$\n",
    "- **Variance**: $1/\\lambda^2$\n",
    "- **PDF**:\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "f_X(x) = \\lambda e^{-\\lambda x}\n",
    "}\n",
    "$$\n",
    "- Taking a look: <img src='img/exponential.png'/>\n",
    "\n",
    "#### Beta \n",
    "- Family of all sorts of distributions over the range from 0 to 1\n",
    "  - e.g.: Your belief in the probability of a heads on a coin that you're not sure is fair.  Think about this, you might most strongly believe $p=0.5$, so it would be peaked there, but you still hold out some probability that $p$ could be anything else from 0 to 1.\n",
    "- **Parameters**:\n",
    "  - $\\alpha$ and $\\beta$: Shape parameters\n",
    "- **Expectation**: $\\alpha/(\\alpha + \\beta)$\n",
    "- **Variance**: $\\frac{\\alpha \\beta}{(\\alpha + \\beta)^2(\\alpha + \\beta + 1)}$\n",
    "- **PDF**: There's no way in hell you'd ever need to know this\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "f_X(x) = \\frac{x^{\\alpha-1}(1-x)^{\\beta - 1}}{B(\\alpha, \\beta)}\n",
    "}\n",
    "$$\n",
    "- Here, $B = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}$ where $\\Gamma$ is the (Gamma Function)[https://en.wikipedia.org/wiki/Gamma_function]\n",
    "- Here's a look: <img src='img/beta.png' style='height:400px'/>\n",
    "\n",
    "#### Student's t\n",
    "- The t-distribution comes from estimating the mean of a normally distributed population when the sample size is small and of unknown variance.\n",
    "- It basically looks like a fat normal distribution (fatter tails, so possibly more varied results).\n",
    "- As the sample size approaches the entire population, it converges to the normal distribution.\n",
    "- Useful in evaluating regression coefficients (we'll come back to this!)\n",
    "- **Parameters**:\n",
    "  - $\\nu=n-1$: The \"degrees of freedom\", where $n$ is the sample size\n",
    "- **Expectation**: 0\n",
    "- **Variance**: $\\nu/(\\nu-2)$\n",
    "- **PDF**: There's even less chance in hell you'd ever have to know this\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "f_X(x) = \\frac{\\Gamma\\left(\\frac{\\nu + 1}{2}\\right)}{\\sqrt{\\pi\\nu}\\Gamma\\left(\\frac{\\nu}{2}\\right)}\\left(1+\\frac{x^2}{nu}\\right)^{-\\frac{\\nu + 1}{2}}\n",
    "}\n",
    "$$  \n",
    "- Here's a look: <img src='img/t.png'/>\n",
    "\n",
    "#### Chi-squared\n",
    "- Distribution of the **sum of squares** of $k$ **independent normal R.V.s**\n",
    "- Useful for both goodness of fit and feature selection (we'll come back to this!)\n",
    "- **Parameters**:\n",
    "  - $k$: Number of normal R.V.s\n",
    "- **Expectation**: $k$\n",
    "- **Variance**: $2k$\n",
    "- **PDF**: In hell, this is the first interview question\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "f_X(x) = \\frac{1}{2^{k/2}\\Gamma\\left(\\frac{k}{2}\\right)}x^{k/2-1}e^{-k/2}\n",
    "}\n",
    "$$\n",
    "- And a look: <img src='img/chi2.png' style='height:400px'/>\n",
    "\n",
    "### Joint Probability Distributions\n",
    "So far we've discussed probability distributions for **single R.V.s**.  What if we have **multiple R.V.s** and we want to know the probability of all possible simultaneous combinations of their respective values?\n",
    "\n",
    "This is where the concept of a **joint probability distribution** comes in.\n",
    "\n",
    "##### Definitions\n",
    "- **Joint Probability Distribution**: For $n$ random variables $X_1, X_2, \\cdots, X_n$ tied to an experiment, maps to a value for all possible combinations of values $(x_1, x_2, \\cdots, x_n)$\n",
    "- **Joint PMF**: Maps to the probability of all possible simultaneous combinations of $(x_1, x_2, \\cdots, x_n)$\n",
    "  - e.g.: For 2 dice rolls, $X_1$ for roll 1 and $X_2$ for roll 2 (pretty trivial example)\n",
    "- **Joint PDF**: Maps to the probability density for all possible simultaneous combinations of $(x_1, x_2, \\cdots, x_n)$\n",
    "  - e.g.: For 2 randomly sampled women, their respective heights as $X_1$ and $X_2$\n",
    "\n",
    "##### Notation\n",
    "- **Joint PMF** for random variables $X$ and $Y$: $p_{X,Y}(x,y) = P(\\{X=x\\}\\cap\\{Y=y\\})=P(X=x\\;\\text{and}\\;Y=y)$\n",
    "- **Joint PDF** for random variables $X$ and $Y$: $f_{X,Y}(x,y)$ the probability density at all points in 2-D (in this case) space\n",
    "\n",
    "#### Again a Note for Continuous PDFs\n",
    "For PMFs it's still easy, we can assign a probability $P(X=x, Y=y)$ to all possible combinations of multiple random variables:\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "P(X=x, Y=y) = p_{X,Y}(x,y)\n",
    "}\n",
    "$$\n",
    "For continuous we can still only speak in ranges.  Thus:\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "P(a\\le X \\le b, c \\le Y \\le d) = \\int\\limits_c^d\\int\\limits_a^bf_{X,Y}(x,y)dxdy\n",
    "}\n",
    "$$\n",
    "\n",
    "#### Marginal Distributions\n",
    "If we want to figure out the PMF or PDF of a single variable (or combination of variables), we simply sum (or integrate) the joint PMF (or PDF) over the other variables.  The resulting PMF (or PDF) is sometimes referred to as the **marginal distribution**:\n",
    "- For Discrete:\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "\\begin{align}p_X(x) = \\sum\\limits_y p_{X,Y}(x,y) \\\\ p_Y(y) = \\sum\\limits_xp_{X,Y}(x,y)\\end{align}\n",
    "}\n",
    "$$\n",
    "- For Continuous:\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "\\begin{align}f_X(x) = \\int\\limits_y f_{X,Y}(x,y)dy \\\\ f_Y(y) = \\int\\limits_xf_{X,Y}(x,y)dx\\end{align}\n",
    "}\n",
    "$$\n",
    "- We can also extend these to more variables $X$, $Y$, and $Z$ (or as many as we like):\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "\\begin{align}p_{X,Y,Z}(x,y,z) = P(X=x, Y=y, Z=z)\\\\ p_{X,Y}(x,y) = \\sum\\limits_zp_{X,Y,Z}(x,y,z) \\\\ p_X(x) = \\sum\\limits_y\\sum\\limits_zp_{X,Y,Z}(x,y,z) \\\\ f_{X,Y}(x,y) = \\int\\limits_zf_{X,Y,Z}(x,y,z)dz \\\\ f_{X}(x) = \\int\\limits_y\\int\\limits_zf_{X,Y,Z}(x,y,z)dydz\\end{align}\n",
    "}\n",
    "$$\n",
    "\n",
    "#### Functions of Multiple R.V.s\n",
    "- We can easily extend our treatment of functions of a single random variable to functions of multiple random variables.\n",
    "- Let R.V. $Z$ be a function of $X$ and $Y$, then we can use the joint probability of $X$ and $Y$ to map out a probability distribution for $Z$.\n",
    "- Thus $Z$ is a R.V. (it has a probability distribution)\n",
    "- For Discrete:\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "Z=g(X,Y) \\rightarrow p_Z(z) = \\sum\\limits_{(x,y)|g(x,y)=z}p_{X,Y}(x,y)\n",
    "}\n",
    "$$\n",
    "- For Continuous:\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "Z=g(X,Y) \\rightarrow f_Z(z) = \\iint\\limits_{(x,y|g(x,y)=z}f_{X,Y}(x,y)dxdy\n",
    "}\n",
    "$$\n",
    "\n",
    "##### Identities for Functions of Multiple R.V.s:\n",
    "- **Linear Expectation**: $Z=aX+bY+c \\rightarrow E[Z] = aE[X] + b E[Y] + c$\n",
    "\n",
    "### Common Multivariable Probability Distributions\n",
    "Here are just a few that might come in handy, but of course there are always so many more!\n",
    "\n",
    "#### Multinomial\n",
    "- The multinomial is like the binomial, except it has more than 2 choices for each independent trial\n",
    "  - e.g.: Rolling a di a bunch of times, how many did you get of each number?\n",
    "- This is a discrete distribution\n",
    "- For $m$ possible choices in each trial, there are $m$ random variables that we are thus tracking, each R.V. is the number of times $k_i$ we got that particular outcome.  The multinomial pmf is a joint pmf across those $m$ variables.\n",
    "- **Parameters**: \n",
    "  - $n$: The number of independent trials\n",
    "  - $\\vec{p}$: A vector of $m$ probabilities $(p_1, p_2, \\cdots,p_m)$, 1 for each of the possible outcomes on each trial\n",
    "    - These probabilities must sum up to 1\n",
    "    - e.g.: Dice rolling: $p=(1/6, 1/6, 1/6, 1/6, 1/6, 1/6)$\n",
    "- **Expectation**: $n\\vec{p}$\n",
    "- **Variance**: $np_i(1-p_i) \\; \\forall \\; i$\n",
    "- **PMF**:\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "{n \\choose k_1,k_2, \\cdots,k_m}p_1^{k_1}p_2^{k_2}\\cdots p_m^{k_m}\n",
    "}\n",
    "$$\n",
    "- Here for instance, is what the \"trinomial\" distribution might look like: <img src='img/multinomial.png'/>\n",
    "\n",
    "#### Dirichlet\n",
    "- This is the multivariate generalization of the Beta Distribution\n",
    "- It is a continuous distribution\n",
    "- **Parameters**:\n",
    "  - $\\alpha$: A vector of shape parameters of whatever dimensionality we're generalizing to\n",
    "    - Remember the Beta distribution had 2 of these parameters, now we have $n$\n",
    "- **Expectation**: $E[X_i] = \\frac{\\alpha_i}{\\sum\\limits_k\\alpha k}$\n",
    "- **Variance**: [http://google.com](http://google.com)\n",
    "- **PDF**: Oh F that noise\n",
    "- Here are a few different looks just 1 dimension up from the Beta, to see if we can visualize what's happening: <img src='img/dirichlet.png'/>\n",
    "\n",
    "#### Multivariate Normal\n",
    "- This is the multivariate generalization of the Gaussian Distribution to $k$ dimensions\n",
    "- It is continuous\n",
    "- **Parameters**:\n",
    "  - $\\vec{\\mu}$: A vector of $k$ means, one for each R.V. aka dimension\n",
    "    - These still control the location of the \"peak\" just in $k$ dimensions :)\n",
    "  - $\\mathbf{\\Sigma}$: The $k$ by $k$ (**Covariance Matrix**)[https://en.wikipedia.org/wiki/Covariance_matrix] for the random variables\n",
    "    - These still control the widths along each axis, just in $k$ dimensions :)\n",
    "- **Expectation**: $\\vec{\\mu}$\n",
    "- **Variance**: $\\mathbf{\\Sigma}$\n",
    "- **PDF**:\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "f_{\\mathbf{X}}(\\vec{x})=(2\\pi)^{-k/2}\\lVert \\mathbf{\\Sigma}\\rVert^{-1/2}e^{-\\frac{1}{2}(\\vec{x}-\\vec{\\mu})^T\\mathbf{\\Sigma}^{-1}(\\vec{x}-\\vec{\\mu})}\n",
    "}\n",
    "$$\n",
    "- Here's a bivariate Gaussian! <img src='img/gaussian2.png'/>\n",
    "\n",
    "### Conditional Probability Distributions\n",
    "We discussed conditional probabilities in terms of events, now let's do it in terms of random variables and distributions.\n",
    "\n",
    "##### Definitions\n",
    "- **Conditional Probability Distribution**: A probability distribution for a R.V. of possible outcomes conditioned on some event having occurred or on the value of another R.V.\n",
    "\n",
    "##### Notation\n",
    "- **Conditioning on an Event $A$**: $p_{X|A}(x) = P(X=x|A)$\n",
    "- **Conditioning on another R.V. $Y$**: $p_{X|Y}(x) = P(X=x|Y=y)$\n",
    "\n",
    "#### Identities\n",
    "- **Discrete Conditioning on an Event**: \n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "p_{X|A}(x) = \\frac{P(\\{X=x\\}\\cap A)}{P(A)}\n",
    "}\n",
    "$$\n",
    "- **Discrete Conditioning on R.V.**: \n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "p_{X|Y}(x) = \\frac{P(X=x, Y=y)}{P(Y=y)} = \\frac{p_{X,Y}(x,y)}{p_Y(y)}\n",
    "}\n",
    "$$\n",
    "- **Continuous Conditioning on R.V.**: \n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "f_{X|Y}(x) = \\frac{f_{X,Y}(x,y)}{f_Y(y)}\n",
    "}\n",
    "$$\n",
    "- **Total Probability Theorem**: If events $A_1, A_2, \\cdots, A_n$ are distjoint events that partition the sample space then:\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "p_X(x) = \\sum\\limits_{i=1}^nP(A_i)p_{X|A_i}(x)\n",
    "}\n",
    "$$\n",
    "- **Relation to Joint PMF**: This is analogous to the chain multiplication rule for conditional probability, aka $P(A\\cap B) = P(B)\\cdot P(A|B)$\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "p_{X,Y}(x,y) = p_Y(y)p_{X|Y}(x|y) = p_X(x)p_{Y|X}(y|x)\n",
    "}\n",
    "$$\n",
    "- **Relation to Joint PDF**: Again, chain multiplication rule for conditional probability\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "f_{X,Y}(x,y) = f_Y(y)f_{X|Y}(x|y) = f_X(x)f_{Y|X}(y|x)\n",
    "}\n",
    "$$\n",
    "- **Relation to Marginal PMF**: \n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "p_X(x) = \\sum\\limits_yp_Y(y)p_{X|Y}(x|y)\n",
    "}\n",
    "$$\n",
    "- **Relation to Marginal PDF**: \n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "f_X(x) = \\int\\limits_y f_Y(y)f_{X|Y}(x|y)dy\n",
    "}\n",
    "$$\n",
    "- **Conditional Expectation**:\n",
    "  - **Discrete on Event**: $E[X|A] = \\sum\\limits_xxp_{X|A}(x)$\n",
    "  - **Function Discrete on Event**: $E[g(X)|A] = \\sum\\limits_xg(x)p_{X|A}(x)$\n",
    "  - **Discrete on R.V.**: $E[X|Y=y] = \\sum\\limits_xxp_{X|Y}(x|y)$\n",
    "  - **Total Expectation on Events** $A_i$: $E[X] = \\sum\\limits_{i=1}^{n}P(A_i)E[X|A_i]$\n",
    "  - **Discrete Total Expectation on R.V.s**: $E[X] = \\sum\\limits_yp_Y(y)E[X|Y=y]$\n",
    "  - **Continuous on Event**: $E[X|A] = \\int\\limits_xxf_{X|A}(x)dx$\n",
    "  - **Function Continuous on Event**: $E[g(X)|A] = \\int\\limits_xg(x)f_{X|A}(x)dx$\n",
    "  - **Continuous Function on R.V.**: $E[X|Y=y] = \\int\\limits_xxf_{X|Y}(x|y)$\n",
    "  - **Continuous Total Expectation on R.V.s**: $E[X] = \\int\\limits_yf_Y(y)E[X|Y=y]dy$\n",
    "  \n",
    "#### Independence of Random Variables\n",
    "Simply put, 2 random variables $X$ and $Y$ are independent if: \n",
    "$$\n",
    "p_X(x) = p_{X|Y}(x|y)\n",
    "$$\n",
    "\n",
    "This also implies that: \n",
    "$$\n",
    "p_{X,Y}(x,y) = p_Y(y)p_{X|Y}(x|y) = p_Y(y)p_X(x)\n",
    "$$\n",
    "\n",
    "Thus, independence implies that the joint probability is a product of the marginal distributions.  This is analogous to our rule with events, where $P(A)P(B)=P(A\\cap B)$ implies independence.\n",
    "\n",
    "In the continuous case:\n",
    "$$\n",
    "f_X(x) = f_{X|Y}(x|y)\n",
    "$$\n",
    "$$\n",
    "f_{X,Y}(x,y) = f_Y(y)f_X(x)\n",
    "$$\n",
    "\n",
    "##### A Few More Independence Identities\n",
    "Remember these only necessarily hold true when events or R.V.s are independent:\n",
    "- $p_{X|A}(x) = p_X(x)$\n",
    "- $E[XY] = E[X]E[Y]$\n",
    "- $E[g(X)h(Y)] = E[g(X)]E[h(Y)]$\n",
    "- $var(X+Y) = var(X) + var(Y)$\n",
    "\n",
    "### Cumulative Distribution Functions\n",
    "We're almost done!  Lastly we're just going to touch briefly on **Cumulative Distribution Functions**, or **CDF**s.  \n",
    "\n",
    "**Definition**: A Cumulative Distribution Function (CDF), represents the probability that a R.V. is less than or equal to a certain value.\n",
    "\n",
    "##### Notation\n",
    "- **CDF**: $F_X(x)$ for both discrete and continuous\n",
    "\n",
    "Here's the definition symbolically for both discrete and continuous variables:\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "F_X(x) = P(X \\le x) = \\begin{cases}\\sum\\limits_{k\\le x}p_X(k), & \\text{if}\\; X \\; \\text{is discrete} \\\\ \\int\\limits_{-\\infty}^{x}f_X(t)dt, & \\text{if}\\; X \\; \\text{is continuous}\\end{cases}\n",
    "}\n",
    "$$\n",
    "\n",
    "#### CDF Identities and Properties\n",
    "- Discrete: $p_X(k) = F_X(k)-F_X(k-1)$\n",
    "- Continuous: $f_X(x) = \\frac{dF_X}{dx}(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing\n",
    "The main goal of today will be to discuss hypothesis testing.  You will frequently hear this referred to as **A/B Testing**, in which you have some experimental treatment to perform and you want to evaluate its effectiveness on a test group vs a control group.\n",
    "\n",
    "Examples might include:\n",
    "- Whether a drug treatment has an effect\n",
    "- Whether your advertising strategy (model!) convinces more users to upgrade\n",
    "\n",
    "A/B testing certainly isn't everything, for instance we might want to test hypotheses about the validity of certain distributions, assumptions, parameters, etc such as:\n",
    "- Is this coin a fair coin?\n",
    "- Is this data normally distributed?\n",
    "- Does this feature have an impact on my target variable?\n",
    "\n",
    "#### (Potentially) Useful Definitions and Identities\n",
    "\n",
    "##### Covariance\n",
    "- How different variables vary together\n",
    "- $cov(X,Y) = E[(X-E[X])(Y-E[Y])]$  \n",
    "\n",
    "##### Correlation\n",
    "- Another measure, the more familiar $r$ for correlation coefficient\n",
    "- Shown here as $\\rho$ for maximal confusion\n",
    "- $\\rho(X,Y) = \\frac{cov(X,Y)}{\\sqrt{var(X)var(Y)}}$\n",
    "\n",
    "##### Variance of Sum of RVs \n",
    "- If you have RVs $X$, $Y$, then the variance of their sum is:\n",
    "  - $var(X+Y) = var(X) + var(Y) + 2cov(X,Y)$  \n",
    "- Generally, for a sequence of RVs $X_i$:\n",
    "  - $var(\\sum\\limits_{i=1}^{n}X_i) = = \\sum\\limits_{i=1}^{n}var(X_i) + \\sum\\limits_{\\{(i,j)|i\\ne j\\}}cov(X_i, X_j)$\n",
    "\n",
    "##### Sums of I.I.D. RVs\n",
    "- If you have a set of Independent, Identically Distributed RVs, s.t.:\n",
    "  - $X_i$ I.I.D with $\\mu$, $\\sigma$  \n",
    "  - $S_n = X_1 + X_2 + \\cdots + X_n$ \n",
    "- Then:\n",
    "  - $E[S_n] = n\\mu$  \n",
    "  - $var(S_n) = n\\sigma^2$  \n",
    "- The mean of them is given by:\n",
    "  - $M_n = \\frac{S_n}{n}$  \n",
    "  - $E[M_n] = \\mu$  \n",
    "  - $var(M_n) = \\frac{\\sigma^2}{n}$  \n",
    "- We can also define another RV $Z_n$ s.t.:\n",
    "  - $Z_n = \\frac{S_n-n\\mu}{\\sigma\\sqrt(n)}$  \n",
    "  - $E[Z_n] = 0$  \n",
    "  - $var(Z_n) = 1$  \n",
    "- **Checking for smarties**: Why would we do this?\n",
    "\n",
    "### Central Limit Theorem\n",
    "- The infinitely celebrated **Central Limit Theorem** makes the following claim:\n",
    "- As $n$ becomes large, $Z_n$ from above becomes Standard Normal  \n",
    "- The **only** strict requirements are:  \n",
    "  - Independence of $X_i$\n",
    "  - Finite mean and variance of $X_i$\n",
    "- **WHOA!**  What?  Why?  How??\n",
    "  - Well, let's take a look...  \n",
    "**CLT for Exponential Distribution**:  \n",
    "<img src='img/exponential_clt.png'/>\n",
    "\n",
    "**CLT for Uniform Distribution**:\n",
    "<img src='img/uniform_clt.png'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CLT: The Rub**    \n",
    "- For $S_n$:  \n",
    "  - Calculate mean, variance of $X_i$.  \n",
    "  - For any value $c$, Calculate normalized value: $z = \\frac{c-n\\mu}{\\sigma\\sqrt{n}}$  \n",
    "  - $P(S_n \\le c) \\approx \\Phi(z)$,  where $\\Phi(z)$ is the **Normal CDF**\n",
    "  - These **standardized scores** are called **z-scores**\n",
    "  - You look up the values for this in a **Standard Normal Table**, which is just the values of the **Normal CDF** at different values of $z$.  \n",
    "  \n",
    "Here's what I mean, visually! <img src='img/normal_cdf.png'/>\n",
    "\n",
    "**A Comment on the CLT Approximation**:  \n",
    "- The normal approximation is increasingly accurate as $n\\rightarrow \\infty$\n",
    "- In practice we generally have specific finite $n$.\n",
    "- It would be useful to know how large $n$ should be before the approximation can be trusted, but there are no simple and general guidelines.\n",
    "- Much depends on whether the distribution of $X_i$ is close to normal and, in particular, whether it is symmetric.  \n",
    "- For example, if the $X_i$ are uniform, then $S_8$ is already very close to normal.  But if the $X_i$ are exponential for instance, a significantly larger $n$ is needed before $S_n$ will converge to normal.\n",
    "- Also, $P(S_n\\le c)$ tends to be more faithful to a normal distribution around the mean of $S_n$.  \n",
    "\n",
    "**Binomial Approximation to Normal**:  \n",
    "For Binomial, you can basically approximate it as a normal distribution with the following identity:  \n",
    "$$\n",
    "\\bbox[aqua,8px]{P(k \\le S_n \\le l) \\approx \\Phi\\left(\\frac{l + 1/2 - np}{\\sqrt{np(1-p)}}\\right) - \\Phi\\left(\\frac{k - 1/2 - np}{\\sqrt{np(1-p)}}\\right)}\n",
    "$$  \n",
    "\n",
    "If $p$ is near 0.5, approximation good for low $n$, if not, need more samples.\n",
    "\n",
    "##### Examples\n",
    "**Polling Error:** \n",
    "- We poll $n$ voters\n",
    "- $M_n$ is the fraction supporting our candidate\n",
    "- Each voter is a Bernoulli RV with unknown parameter $p$\n",
    "- $E[M_n] = np$\n",
    "- $var(M_n) = p(1-p)/n$\n",
    "- $M_n \\approx N(np, p(1-p))$\n",
    "- Let's use a conservative upper bound for variance instead, of 1/4 (maximum possible for Bernoulli)\n",
    "- We can derive a **margin of error** on our estimate of $p$ to a certain level of confidence\n",
    "- If variance is 1/4, then the standard deviation is $1/(2\\sqrt{n})$\n",
    "- So say, a 95% confidence interval would have a margin of error of:\n",
    "  - $1.96/\\sqrt{n}$\n",
    "  - **Exercise**: Can you work this out on your own?  Don't try now, later.\n",
    "\n",
    "### Weak Law of Large Numbers\n",
    "The **sample mean** of a large number of I.I.D. RVs is very close to its actual mean, with high probability:  \n",
    "$$\n",
    "\\bbox[aqua, 8px]{P(|M_n-\\mu| \\ge \\epsilon)\\rightarrow 0, \\quad \\text{as}\\; n \\rightarrow \\infty\n",
    "}\n",
    "$$  \n",
    "\n",
    "### Strong Law of Large Numbers\n",
    "The **sample mean** converges to the true mean as $n\\rightarrow \\infty$:  \n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "P\\left(\\lim\\limits_{n\\rightarrow \\infty}\\frac{X_1 + X_2 + \\cdots + X_n}{n} = \\mu\\right) = 1\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability vs Statistics\n",
    "Statistics relies on many of the probability concepts we've discussed so far, but statistics is also different.  Probability relies on a set of well-defined axioms to explain an uncertain situation in as complete a way as possible.  Statistics, in particular statistical inference, is an art.  There isn't necessarily any best method to approaching things, unless one relies on a considerable set of constraints and/or assumptions.  Thus, what we can do is narrow down our search for the \"right\" method by seeking certain desirable characteristics.  This has endless possibilities, today we will touch on a few.\n",
    "\n",
    "### Bayesian vs Classical Viewpoint\n",
    "Today we are concerned with **Parameter Estimation**.  There are 2 different pictures of how to interpret parameter estimation:  \n",
    "- The Bayesian Viewpoint: views the parameter as an inherently random variable whose distribution we are seeking to discover.\n",
    "- The Classical Viewpoint: views the parameter as fixed and we're just lacking the knowledge of what it is.  We seek range estimates, or **confidence intervals** with a certain probability of \"catching\" the **true value** of the parameter.\n",
    "\n",
    "Today, we're going to focus on the classical approach.  We'll come back to Mr. Bayes later!\n",
    "\n",
    "### Classical Parameter Estimation\n",
    "Consider a set of observations $X=(X_1,X_2, \\cdots, X_n)$ whose distribution depends on some unknown underlying parameter $\\theta$ (note: $\\theta$ can be a vector of parameters).  Our goal in parameter estimation is to develop an estimator of $\\theta$, called $\\hat{\\Theta}_n$.  Thus, the distribution for $\\hat{\\Theta}_n$ will be a function of $\\theta$ as well.\n",
    "\n",
    "##### Notation\n",
    "- **Parameter to Estimate**: Usually $\\theta$\n",
    "- **Estimator based on Random Sample of n Observations**: $\\hat{\\Theta}_n$\n",
    "- **Upper/Lower Bounds for Confidence Interval on Estimator**: $\\hat{\\Theta}_{n}^{+/-}$\n",
    "\n",
    "#### Confidence Intervals\n",
    "- A confidence interval is a range estimate for a parameter $\\theta$ that will catch the true value of $\\theta$ with some specified confidence level.  \n",
    "- That is, for example, a 95% confidence interval for $\\theta$ will contain the true $\\theta$ 95% of the time over many tests of random samples.\n",
    "- Remember, the confidence interval here is the random entity (determined by a random sample of observations that we take).  In the classical picture, $\\theta$ is fixed, not random.\n",
    "- You typically set some small value $\\alpha$ (often 0.05) s.t. a $1-\\alpha$ confidence interval for $\\theta$ indicates the following:\n",
    "$$\n",
    "\\bbox[aqua, 8px]{\n",
    "P_{\\theta}(\\hat{\\Theta}_{n}^{-} \\le \\theta \\le \\hat{\\Theta}_{n}^{+}) >= 1-\\alpha\n",
    "}\n",
    "$$\n",
    "- **Confidence Interval for the Mean from Sum of I.I.D. RVs**: $P(|M_n-\\mu| \\ge \\epsilon)\\le \\delta, \\quad \\forall \\; n\\ge n_0$  \n",
    "  - This is a $1-\\delta$ confidence interval.  $M_n$ will be within $\\epsilon$ of $\\mu$ with $1-\\delta$ confidence.\n",
    "\n",
    "##### Forming a Confidence Interval\n",
    "- To form a confidence interval, you have to choose a **test statistic**, that is, a distribution for which you have a known **CDF**.  \n",
    "- This is often the **Normal Distribution**, but it can also be other distributions like the **Student's T Distribution**\n",
    "- Let's call your chosen CDF $\\Phi(z)$\n",
    "- To form your confidence interval of level $\\alpha$, you just take the values from $\\Phi(z)=\\alpha/2$ to $\\Phi(z)=1-\\alpha/2$\n",
    "\n",
    "Here's an example of what that looks like with the **Standard Normal Distribution**, for which $\\Phi(-1.96)=0.025$ and $\\Phi(1.96)=0.975$ would give you a 95% confidence interval:\n",
    "<img src='img/ci.jpg'/>\n",
    "\n",
    "##### Sample Mean and Variance\n",
    "- **Sample Mean**: The mean of the sample\n",
    "- **Sample Variance**: The variance of the sample\n",
    "- **Other Estimates of Variance**: \n",
    "  - Known Distribution: You know the distribution of each individual $X_i$, so you can represent the variance in terms of the unknown parameter you're trying to estimate\n",
    "    - e.g.: Bernoulli RV: $\\sigma = p(1-p)$\n",
    "  - Conservative Upper Bound: You use the absolute worst case variance, to be as cautious as possible in you confidence intervals and tests\n",
    "    - e.g.: Bernoulli RV: Maximum variance is if $p=0.5\\rightarrow 0.25$\n",
    "\n",
    "##### Confidence Intervals and Testing with Known Variance\n",
    "Use a normal distribution! (Probably)\n",
    "\n",
    "##### Confidence Intervals with Unknown Variance\n",
    "Use a Students-T distribution!\n",
    "\n",
    "### Binary Hypothesis Testing\n",
    "This is concerned with choosing between 2 hypotheses.  \n",
    "\n",
    "##### Definitions\n",
    "- **Null Hypothesis**: $H_0$, the presumed initial hypothesis that you either accept or reject\n",
    "- **Alternative Hypothesis**: $H_1$, the alternative to the Null Hypothesis.\n",
    "- **Type 1 Error**: You reject $H_0$ when you should've accepted\n",
    "- **Type 2 Error**: You accept $H_0$ when you should've rejected\n",
    "\n",
    "One technique for choosing between 2 hypotheses is to determine the **likelihood ratio** of each.  Let's do an example:  \n",
    "\n",
    "**Worked Example: Flipping Coins**  \n",
    "We flip a coin $n$ times and find $k$ heads.  We want to decide between 2 options for $p$, the probability of a heads on a single flip.  \n",
    "- $H_0$: $p=0.5$  \n",
    "- $H_1$: $p=0.7$  \n",
    "- **Likelihood Ratio**: This is the ratio of the likelihood of $H_1$ to $H_0$:\n",
    "  - $L(n,p; k) = \\frac{{n \\choose k}0.7^k(1-0.7)^{n-k}}{{n \\choose k}0.5^k0.5^{n-k}} = \\frac{0.7^k0.3^{n-k}}{0.5^n}$\n",
    "  - Clearly this is an increasing function of $k$, so we can solve for the minimum value of $k$ at which we'd choose $H_1$ over $H_0$.\n",
    "- Going a level deeper, you would actually define an acceptance and reject region for both hypothesis, but that's really more getting into significance testing...so now that you mention it...\n",
    "\n",
    "### Significance Testing\n",
    "Binary Hypothesis testing is grand and all, but more commonly, you don't have an explicitly defined alternative hypothesis, and you're just testing whether to accept or reject the null hypothesis at a given confidence level.  This is **significance testing**.\n",
    "\n",
    "##### Definitions\n",
    "- **Null Hypothesis**: $H_0$, the presumed initial hypothesis that you either accept or reject\n",
    "- **Alternative Hypothesis**: $H_1$, the alternative to the Null Hypothesis.  You don't explicitly confirm this hypothesis, you simply may reject the null hypothesis with a certian degree of confidence.\n",
    "\n",
    "Here is where our knowledge of confidence intervals and the Central Limit Theorem will really come in handy.  Let's do some worked examples:\n",
    "**Example: Do I Have a Fair Coin?**:  \n",
    "- $n$ tosses with $k$ heads, unknown probability $p$ of a heads\n",
    "- $H_0$: $p=0.5$\n",
    "- $H_1$: $p \\ne 0.5$\n",
    "- **Significance Level** $\\alpha$: This is the probability of Type 1 error, i.e. that we will reject when we should've accepted $H_0$.  Essentially, we're taking a $1-\\alpha$ confidence interval, and $100\\cdot \\alpha$% of the time we will get an experimental value that was fairly extreme and thus mislead us into thinking $H_0$ was wrong.\n",
    "  - $\\alpha=0.05$\n",
    "- Say we flip 1000 times and get 472 heads, is the coin fair?\n",
    "- Here are the steps:\n",
    "  - Approximate the binomial as normal under our null hypothesis, aka $n=1000$ and $p=0.05$ (using the normal approximation for binomial from above)\n",
    "  - Calculate the z-score for 472 heads against this normal distribution\n",
    "  - Use a normal CDF table to look up the value.  If $\\alpha/2 \\le z \\le 1-\\alpha/2$, then we **do not** reject the null hypothesis that the coin is fair, at a 5% significance level.\n",
    "- If we follow those steps for our case, we see that we would've need less than 470 or more than 530 heads to reject our null hypothesis at this significance level.\n",
    "\n",
    "#### General Steps for Significance Testing:\n",
    "1. Choose a Test Statistic, aka distribution you are ascribing to your test variable\n",
    "  - This could be Standard Normal, t, Chi-squared, etc\n",
    "2. Choose a significance level $\\alpha$\n",
    "3.  Determine the values representing the limits of your rejection region by looking up the CDF for your test statistic under the assumptions of the null hypothesis\n",
    "4. Reject the null hypothesis if the observed value on your test statistic falls outside those bounds.\n",
    "\n",
    "**Example: A/B Testing - Does my model make a difference!?**  \n",
    "- You have a software product for which you are running a \"freemium\" model.  That is, you have a basic product that's free, but users can pay for a license to upgrade to premium features.\n",
    "- You have built a model for targeted advertising, which you are banking your livelihood on.  You hope that it will properly target adds so that **a higher percentage of users will choose to upgrade** under this new strategy.\n",
    "- How would you test this out?\n",
    "- This is called an **A/B Test**.\n",
    "  - First you need to create 2 different (randomly sampled) test groups of the user base, of size $n_1$ and $n_2$.  You will then try out the different alternatives (old ad strategy and your new model) on the 2 groups.  From there, you perform significance testing to determine if your model is making a difference or not.\n",
    "- Let's follow our steps for significance testing:\n",
    "  - Define the variables of interest:\n",
    "    - $\\theta_{old}$: Probability of user upgrades with the old ads\n",
    "    - $\\theta_{new}$: Probability of user upgrades with the new ads\n",
    "    - Each user responds like a **Bernoulli** random variable with unknown parameter $p$\n",
    "    - $p$ is $\\theta_{old}$ for group A, with the old ads\n",
    "    - $p$ is $\\theta_{new}$ for group B, with the new ads\n",
    "  - $H_0$: $\\theta_{old}=\\theta_{new}$\n",
    "  - $H_1$: $\\theta_{old} \\ne \\theta_{new}$\n",
    "  - **Sample Means**:\n",
    "    - $\\hat{\\Theta}_{old}=\\frac{1}{n_1}\\sum\\limits_{i=1}^{n_1}X_i$\n",
    "    - $\\hat{\\Theta}_{new} = \\frac{1}{n_2}\\sum\\limits_{i=1}^{n_2}Y_i$\n",
    "  - **Sample Variances**:\n",
    "    - $\\hat{S}_{old} = \\frac{\\theta_{old}(1-\\theta_{old})}{n_1}$\n",
    "    - $\\hat{S}_{new} = \\frac{\\theta_{new}(1-\\theta_{new})}{n_1}$\n",
    "  - We're really interested in the **difference between the 2 groups**, aka $\\theta_{new}-\\theta_{old}$\n",
    "    - Because they're independent and normally distributed (for suitable n):\n",
    "      - $\\theta_{new}-\\theta_{old}$ is approximately normal with:\n",
    "        - Sample Mean: $\\hat{\\Theta}_{new}-\\hat{\\Theta}_{old}$\n",
    "        - Population Variance: $\\frac{\\theta_{new}(1-\\theta_{new})}{n_1} + \\frac{\\theta_{old}(1-\\theta_{old})}{n_1}$\n",
    "  - **Under the Null Hypothesis**:\n",
    "    - $\\theta_{new}=\\theta_{old} = \\theta$\n",
    "    - We don't know the variance of $\\hat{\\Theta}_{new}-\\hat{\\Theta}_{old}$ but we can estimate it by pluggin in an estimator for $\\theta$ in the variance equation above:\n",
    "      - $\\hat{\\Theta} = \\frac{\\sum\\limits_{i=1}^{n_1}X_i + \\sum\\limits_{i=1}^{n_2}Y_i}{n_1+n_2}$\n",
    "      - $\\hat{\\sigma}^2 = \\left(\\frac{1}{n_1} + \\frac{1}{n_2}\\right)\\hat{\\Theta}(1-\\hat{\\Theta})$\n",
    "  - Now we have an approximately normal distribution for $\\hat{\\Theta}_{new}-\\hat{\\Theta}_{old}$ with an estimator for both it's mean and variance.\n",
    "  - So we reject $H_0$ at 0.05 significance if:\n",
    "    - $\\frac{\\lvert\\hat{\\Theta}_{new}-\\hat{\\Theta}_{old}\\rvert}{\\hat{\\sigma}} \\gt 1.96$\n",
    "\n",
    "##### One-Tailed vs Two-Tailed Tests\n",
    "What we've done here is what's called a Two-Tailed Test.  We're essentially looking for deviations from the null hypothesis in both directions.  If we are expecting one treatment group to be higher than the other, it might make more sense to perform a One-Tailed test.  This isn't too complex, you simply look for the CDF value of $1-\\alpha$ instead of $\\alpha/2$ and $1-\\alpha/2$.\n",
    "\n",
    "Here's a picture to demonstrate: <img src='img/significance1.png'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
