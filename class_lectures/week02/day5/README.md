### Plan for Friday, Sep 30

#### Overview

So last night I lost my mind a little bit.  Yesterday you got a great practical intro to **probability theory** with Ling.  I decided that I wanted to put together a formal treatment of probability and statistics for you, as it's a hugely important core skill in data science.  **Machine Learning** and **"Statistical Learning"** have come to mean the same thing, and most hiring managers will expect you to speak the language as statistics as you do English (or German, Nils :smile:).  I see a lot of data science candidates who do know how to answer some probability brain teasers but sadly just aren't fully comfortable with the core concepts underlying it.  **You will not be those candidates**.

I say I lost my mind because (as Ling said) of course Probability Theory is a whole college course in itself and then some.  Tackling it in a morning is not realistic.  So after a whole night spent on a notebook, there is still so much more out there!

However, here is how I'm seeing this:
- We can get through this in a 3-part lecture that we'll do over the next few days.
- We will derive things from first principles, rather than just memorizing a bunch of foreign formulas.
- Think of this as **both a lecture and reference material for you for the future**.  Today's lecture alone is probably a few chapters of a textbook.
- I really think/hope the discussion should help demystify some of the scary mathematical notation that surrounds probability/stats.
- This should make you more confident with future mathematical notation in here in general.
- At the end of this, my goal is that you all "speak the language", not just by memorization, but with a deeper intrinsic understanding.

My final thought on why this is necessary is as follows.  As I watched some of you nodding away on problems yesterday I saw just as many grasping to keep up with the various common probability problems.  My goal is that after the next few days, everyone will be at that same level of complete confidence when faced with a probability or statistics concept.

So if you took semesters of statistics in college and some of this seems obvious at first, bear with me.  I think you might just feel the refresher of things from the ground up will solidify your existing base, and perhaps you'll (re)learn a few tricks too.  Similarly, if you've always gotten tied up with problems in this field, stick with it.  This treatment should break down the fear that those big scary math equations might stir up.

**Remember:**
* You need to have your Luther scraping **complete** by **today**
* Benson challenges are due **Monday**
* Pandas challenges are due **10/10**

#### Schedule

**9:00 am**: On Fridays, we do formal academic treatments :sob:

**9:15 am**: Pair Programming:
* Do you understand probability?
  * [Pair: Conditional Probability](pair-conditional-prob.md)

Pairings:  

| Partner1 | Partner2|
|----------|---------|
| Nick | Ron |
| Bob | Rohan |
| Rebecca | Zach |
| Veena | Josh |
| D.H | Catherine |
| Andrea | James |
| Sam | Sarick |
| Will | Nils |
| Kevin | Li |
| Travis | Daniel |
| Kyle | Kaushik |

**10:15 am**: [Demystifying Probability: Part I](Demystifying_Probability.ipynb)

**12:00 pm**: $P(Lunch) = 1 - P(\emptyset)$

**1:30 pm**: Investigation Presentation: Sarick Shah on Predicting March Madness

**1:45 pm**: Work work work work work
* [Project Luther](/projects/02-luther) Web Scraping, finish today!
* [Benson Challenges](/challenges/01-data_munging)
* [Pandas Challenges](/challenges/02-pandas)

**6:00 pm:** Happy Weekend!  2 weeks down!
