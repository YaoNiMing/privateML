{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching package metadata .......\n",
      "Solving package specifications: ..........\n",
      "\n",
      "# All requested packages already installed.\n",
      "# packages in environment at /Users/veenakumar/anaconda2:\n",
      "#\n",
      "beautifulsoup4            4.5.1                    py27_0  \n",
      "Fetching package metadata .......\n",
      "Solving package specifications: ..........\n",
      "\n",
      "# All requested packages already installed.\n",
      "# packages in environment at /Users/veenakumar/anaconda2:\n",
      "#\n",
      "requests                  2.11.1                   py27_0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "!conda install beautifulsoup4 --yes\n",
    "from bs4 import BeautifulSoup\n",
    "!conda install requests --yes\n",
    "import requests\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#***NOTE*** Commented this cell out because it only needed to be run ONCE.\n",
    "\n",
    "\n",
    "# #STEP 1: This is the first \"for loop\". Scrape Box Office Mojo to get the html data. For this project, I am using the top 100 \n",
    "# #domestic gross movies from each year starting from 2000.\n",
    "# #STEP 2: This is the second \"for loop\". Define a function to grab only the urls from each of the above 16 pages. Theoretically\n",
    "# #there should be 1600 urls. \n",
    "\n",
    "# links = []\n",
    "\n",
    "# for yr in range(2000,2017):\n",
    "#     url = 'http://www.boxofficemojo.com/yearly/chart/?yr={}&view=releasedate&view2=domestic&sort=gross&order=DESC&&p=.htm'.format(yr)\n",
    "#     response = requests.get(url)\n",
    "#     page = response.text\n",
    "#     soup = BeautifulSoup(page)\n",
    "#     for link in soup.findAll('a'):\n",
    "#         if 'href' in link.attrs:    \n",
    "#             if 'movies/?id' in link['href']:\n",
    "#                 links.append('http://boxofficemojo.com{0}'.format(link['href']))    \n",
    "\n",
    "# #Gives me a total of 1717 links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#***NOTE*** Commented this cell out because it only needed to be run ONCE.\n",
    "\n",
    "\n",
    "# #STEP 3: Grabbing the html data for individual movie pages and saving it to my local drive. \n",
    "# #Advantage of having it local means I will not have to keep accessing Box Office Mojo over\n",
    "# #multiple days every time I want to retrieve data.\n",
    "\n",
    "# def grab_and_save_pages(links):\n",
    "#     for i in links:\n",
    "#         response = requests.get(i)\n",
    "#         page = response.text\n",
    "#         soup = BeautifulSoup(page)\n",
    "#         soup = soup.prettify(\"utf-8\")\n",
    "#         title = i.split('=')[1]\n",
    "#         with open('/Users/veenakumar/Desktop/Projects/Luther/BomData/%s'%title, \"wb\") as f:\n",
    "#             f.write(soup)\n",
    "            \n",
    "# grab_and_save_pages(links)\n",
    "\n",
    "# #Resulted in 1701 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Running the above step again to get the Foreign data page. \n",
    "import os\n",
    "path = '/Users/veenakumar/Desktop/Projects/Luther/BomData/'\n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith('htm'):\n",
    "        url = 'http://www.boxofficemojo.com/movies/?page=intl&id={}'.format(filename)\n",
    "        response = requests.get(url)\n",
    "        page = response.text\n",
    "        soup = BeautifulSoup(page)\n",
    "        soup = soup.prettify(\"utf-8\")     \n",
    "        title = url.split('=')[2]\n",
    "        with open('/Users/veenakumar/Desktop/Projects/Luther/BomForeign/%s'%title, \"w\") as f:\n",
    "            f.write(soup)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adjusted = {2000: 5.39, 2001: 5.66, 2002: 5.81, 2003: 6.03, 2004: 6.21, 2005: 6.41, 2006: 6.55, 2007: 6.88, 2008: 7.18, 2009: 7.50, 2010: 7.89, 2011: 7.93, 2012: 7.96, 2013: 8.13, 2014: 8.17, 2015: 8.43, 2016: 8.66}\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_values_tags(datafile, field_name):\n",
    "    soup = BeautifulSoup(open(datafile))\n",
    "    obj = soup.find(field_name).text\n",
    "    return obj\n",
    "\n",
    "def get_values_text(datafile, field_name):\n",
    "    soup = BeautifulSoup(open(datafile))\n",
    "    obj = soup.find(text=re.compile(field_name))\n",
    "    if not obj: \n",
    "        return None\n",
    "    next_sibling = obj.findNextSibling()\n",
    "    if next_sibling:\n",
    "        return next_sibling.text \n",
    "    else:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = '/Users/veenakumar/Desktop/Projects/Luther/BomData/'\n",
    "\n",
    "fields_tags = ['title']\n",
    "fields_text_neighbor = ['Domestic Total','Distributor','Release Date','Genre:','Runtime','MPAA Rating','Production Budget']\n",
    "movie_dict = {}\n",
    "\n",
    "def make_dict_tags(fields):\n",
    "    for field in fields:\n",
    "        for filename in os.listdir(path):\n",
    "            if filename.endswith('htm'): \n",
    "                datafile = path+filename\n",
    "                if field in movie_dict:\n",
    "                    movie_dict[field].append(get_values_tags(datafile,field))\n",
    "                else:\n",
    "                    movie_dict[field] = [get_values_tags(datafile,field)]\n",
    "\n",
    "                    \n",
    "def make_dict_text(fields):\n",
    "    for field in fields:\n",
    "        for filename in os.listdir(path):\n",
    "            if filename.endswith('htm'): \n",
    "                datafile = path+filename\n",
    "                if field in movie_dict:\n",
    "                    movie_dict[field].append(get_values_text(datafile,field))\n",
    "                else:\n",
    "                    movie_dict[field] = [get_values_text(datafile,field)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Getting all the titles.\n",
    "make_dict_tags(fields_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Getting a few more fields.\n",
    "make_dict_text(fields_text_neighbor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Turn dictionary so far into a df.\n",
    "movie_data = pd.DataFrame(movie_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Stripping the spaces around the values\n",
    "for value in movie_dict.itervalues():\n",
    "    for i in range(len(value)):\n",
    "        value[i] = str(value[i])\n",
    "        value[i] = value[i].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#**NOTE: Only run this once. Specifically for titles. Commented out so it won't be run twice.\n",
    "# #Stripping titles.\n",
    "# for value in movie_dict.itervalues():\n",
    "#     for i in range(len(value)):\n",
    "#         value[i] = value[i].split('(')[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Saving the data so far!\n",
    "movie_data.to_csv('/Users/veenakumar/Desktop/Projects/Luther/Luther_Movies_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Parse Revenue\n",
    "\n",
    "def foreign(path,texts):\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith('htm'):\n",
    "            datafile = path+filename\n",
    "            soup = BeautifulSoup(open(datafile))                \n",
    "            htmltag = soup.find(\"div\", class_=\"mp_box_content\").find(text=re.compile(texts))\n",
    "            if htmltag:\n",
    "                field_value = htmltag.parent.parent.findNextSibling().text.strip()\n",
    "            else:\n",
    "                field_value = None\n",
    "            if texts in movie_dict:\n",
    "                    movie_dict[texts].append(field_value)\n",
    "            else:\n",
    "                movie_dict[texts] = [field_value]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Extracting release year.\n",
    "movie_data['Release Yr'] = [row[-4:] for row in movie_data['Release Date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Adjust for inflation.\n",
    "\n",
    "current = 8.66\n",
    "adjusted = {2000: 5.39, 2001: 5.66, 2002: 5.81, 2003: 6.03, 2004: 6.21, 2005: 6.41, 2006: 6.55, 2007: 6.88, 2008: 7.18, 2009: 7.50, 2010: 7.89, 2011: 7.93, 2012: 7.96, 2013: 8.13, 2014: 8.17, 2015: 8.43, 2016: 8.66}\n",
    "\n",
    "def convert_to_num(dataframe,column):\n",
    "    for row in dataframe[column]:\n",
    "        num = row.replace('$','').replace(',','')\n",
    "        if num != 'None':\n",
    "            num = int(num)\n",
    "        else:\n",
    "            num = 0\n",
    "        return num\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(len(movie_data)):\n",
    "#     row = movie_data['Release Yr'][i]\n",
    "#     rate = current/adjusted[int(row)]\n",
    "#     movie_data['Domestic Total'][i] = int(movie_data['Domestic Total'][i])*rate\n",
    "# return movie_data['Domestic Total'][i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convert_to_num(movie_data,'Domestic Total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
